---
engine: julia
---

:::{.content-visible when-format="pdf"}
\HeaderNumbered
:::


:::{.hidden}
{{< include mathematics.qmd >}}

```{julia}
#| echo: false
#| output: false

using Pkg
Pkg.activate(".")
```
:::

:::{.content-hidden unless-format="html"}
```{julia}
#| echo: false
#| output: false

using WGLMakie
WGLMakie.activate!()
```
:::

:::{.content-hidden when-format="html"}
```{julia}
#| echo: false
#| output: false

using CairoMakie
CairoMakie.activate!()
```
:::

# A Primer on Dynamical Systems {#dynamical-systems-theory}

We have motivated the entire thesis with the usefulness of the knowledge and of the understanding of synchronization in neuroscience. However, we will not describe any experiments performed on real couples of neurons in a lab. Instead, we shall deal with the mathematical abstraction for the studied object, e.g. the coupled neurons.

This abstraction is typically called a (mathematical) model (of the reality). The model should, in theory, capture all the important characteristics of the underlying reality. If the state of the model causally evolves in time, e.g. a model of neuron starts spiking, we often use a *dynamical system* as the model. On the other hand, if the governing rules are noncausal due to the dependence on some past states of the system, the arising dynamical system becomes infinite dimensional. For better "mathematical ergonomics" we will thus define a *semidynamical system*.

## Dynamical Systems {#sec-dynamical-systems}

First and foremost, we will formally introduce the notion of a *dynamical system*, along with its properties. This section is mostly based on @Kuznetsov2023 and @Pribylova2021, with @Sevcik2021 being a valuable inspiration for the structure of this section.

:::{#def-dynamical-system}
##### Dynamical System

A *dynamical system* is a triple $\set{\timeSet, \stateSpace, \evolOp^t}$, where $\timeSet \subseteq \R$ (*time*) endowed with addition $+$ is a subgroup of $(\R, +)$, $\stateSpace$ is a metric space (called a *state space*), and $\set{\evolOp^t}_{t \in \timeSet}$ is a family of evolution operators parametrized by $t \in \timeSet$, such that $\evolOp^t : \stateSpace \to \stateSpace$ maps a certain point $x^0 \in \stateSpace$ to some other state $x_t = \evolOp^t x^0 \in \stateSpace$.
:::

In the @def-dynamical-system, the time set $\timeSet$ can take on various forms. In ecology, we often see a discrete $\timeSet = \N_0$ or $\timeSet = \Z$ representing a yearly interval between measurements of our system. On the other hand, in physics (and neuroscience) we typically employ $\timeSet = \R$ as we are concerted with even the shortest time intervals and associated changes. Similarly, the exact choice of the state space $\stateSpace$ is dependent of the system in question, but typically we use $\R^n$.

Right now, nothing in the @def-dynamical-system guarantees the system does not abruptly change state, because in general $x \neq \evolOp^0 x$. If this equality does not hold for at least one $x \in \stateSpace$, then such system is called *stochastic*.

:::{#def-deterministic-dynamical-system}
##### Deterministic Dynamical System

A dynamical system, see @def-dynamical-system, is called *deterministic* if and only if the following condition is fulfilled
$$
\evolOp^0 = \id,
$$ {#eq-det-dyn-sys}
in other words $\forall x \in \stateSpace: x = \evolOp^0 x$.
:::

Onwards, we will predominantly use deterministic dynamical systems. Another assumption we shall make throughout this thesis is that the "laws of nature" do not change in time, i.e., we presume the dynamical system in question is autonomous (although it may depend on the past).

:::{#def-autonomous-dynamical-system}
##### Autonomous Dynamical System

A deterministic dynamical system, see @def-deterministic-dynamical-system, is called *autonomous* if and only if the following condition is fulfilled
$$
\forall t,s \in \timeSet: \evolOp^{t+s} = \evolOp^{t} \circ \evolOp^{s},
$$ {#eq-autonomous-dyn-sys}
in other words $\forall x \in \stateSpace \, \forall t,s \in \timeSet: \evolOp^{t+s} x = \evolOp^t (\evolOp^s x)$.
:::

Most often, a dynamical system is given implicitly by a *differential* or *difference* equation. For example, in population dynamics, one of the earliest models, the *Verhulst model of population*[^verhulst], can prescribed by an ordinary differential equation (ODE)
$$
\dot{x}(t) = \deriv {x(t)} t = x(t) \cdot r_0 \cdot \brackets{1 - \frac {x(t)} K},
$$ {#eq-ode-verhulst}
or a *difference equation*
$$
x(t+1) = x(t) \cdot r_0 \cdot \brackets{1 - \frac {x(t)} K}.
$$ {#eq-difference-verhulst}

[^verhulst]: The equation ([-@eq-ode-verhulst]) describes the [Verhulst](https://en.wikipedia.org/wiki/Pierre_Fran%C3%A7ois_Verhulst) model of a population (and its growth, characterized by $r_0$) in some closed environment with some finite capacity (controlled by $K$).

### Basic Concepts

In this section, we shall introduce basic concepts regarding dynamical systems including, but not limited to, notions of certain special solutions and their stability. Little comment beside the definitions themselves will be provided, as an interested reader can find much more in 
<!-- TODO: Add citations -->

:::{#def-orbit}
##### Orbit

An *orbit (trajectory)* with an *initial point* $x_0 \in \stateSpace$ is an ordered subset of the state space $\stateSpace$,
$$
\Orbit{x_0} = \set{x \in \stateSpace \divider x = \evolOp^t x_0, \forall t \in \timeSet \text{ such that } \evolOp^t x_0 \text{ is defined}}
$$

In the case of a continuous dynamical system, the orbits are *oriented curves* in the state space. For a discrete dynamical systems, they become sequences of points in $\stateSpace$.
:::

:::{#def-phase-portrait}
##### Phase Portrait
A *phase portrait* of a dynamical system is a partitioning of the state space into trajectories.
:::

:::{#def-equilibrium}
##### Equilibrium

A point $x^* \in \stateSpace$ is called an *equilibrium* (fixed point) if $\evolOp^t x^* = x^*$ for all $t \in \timeSet$.
:::

:::{#def-cycle}
##### Cycle

A *cycle* is a periodic orbit, namely a non-equilibrium orbit $L$, such that each point $x_0 \in L$ satisfies $\evolOp^{t + T} x_0 = \evolOp^{t} x_0$ with some $T > 0$, for all $t \in \timeSet$. The smallest admissible $T$ is called the *period* of the cycle $L$.
:::

:::{#def-invariant-set}
##### Invariant Set

An *invariant set* of a dynamical system $\set{\timeSet, \stateSpace, \evolOp^t}$ is a subset $\obj S \subset \stateSpace$ which satisfies
$$
x \in \obj{S} \implies \evolOp^t x \in \obj{S} \; \forall t \in \timeSet.
$$
:::

:::{#def-limit-point}
##### $\omega$-limit and $\alpha$-limit Point

A point $x_* \in \stateSpace$ is called an *$\omega$-limit point* (resp. $\alpha$-limit point) of the orbit $\Orbit{x_0}$ starting at $x_0 \in \stateSpace$ if their exists a sequence of times $\seqnc{t}{k}{1}{\infty} \subseteq \timeSet$ with $t_k \to \infty$ (resp. $t_k \to - \infty$), such that
$$
\evolOp^{t_k} x_0 \onBottom{\longrightarrow}{k \to \infty} x_*.
$$
:::

:::{#def-limit-set}
##### $\omega$-limit and $\alpha$-limit Set

A set $\obj \Omega(\Orbit{x_0})$ of all $\omega$-limit points of the orbit $\Orbit{x_0}$, see @def-limit-point, is called an $\omega$-limit set. Similarly, a set $\obj A(\Orbit{x_0})$ of all $\alpha$-limit points of the orbit $\Orbit{x_0}$ is called an $\alpha$-limit set.

Lastly, a set $\limitSet(\Orbit{x_0}) = \obj \Omega(\Orbit{x_0}) \cup \obj A(\Orbit{x_0})$ of all limit points of the orbit $\Orbit{x_0}$ is called its *limit set*.
:::

<!--  FIXME: Add, but I am not sure of the translation
:::{#def-limit-invariant-loop}
##### Limit invariant loop

::: -->

:::{#def-limit-cycle}
##### Limit Cycle

A cycle of a continuous-time dynamical system, in a neighborhood of which there are no other cycles, is called a *limit cycle*.
:::

::: {.callout-note #nte-limit-cycle}
##### Equivalent Definition of a Limit Cycle

Equivalently to @def-limit-cycle, one can define a *limit cycle* as a cycle, which is the limit set, see @def-limit-set, of orbits in its neighborhood.
:::

<!-- TODO: Add citations (use files/, Kuznetsov...) -->

:::{#def-invariant-set-stable}

An invariant set $S_0$ is called 

1. **Lyapunov stable** if for any sufficiently small neighborhood $U \supset S_0$ there exists a neighborhood $V \supset S_0$ such that $\evolOp^t x \in U$ for all $x \in V$ and all $t > 0$;
2. **asymptotically stable** there exists a neighborhood $U_0 \supset S_0$ such that $\evolOp^t x \to S_0$ for all $x \in U_0$, as $t \to +\infty$;
3. **stable** if it is both *Lyapunov* and *asymptotically stable*;
4. **unstable** if it is not *stable*.
:::

Stable invariant set is called an *attractor*, whereas if the invariant set is unstable it is called a *repeller*.

#### Topologically Equivalent Dynamical Systems

<!-- TODO: Add refs to section -->
So far, we have described dynamical systems mainly in general terms. Later, we will get to concrete examples of dynamical systems, primarily from the neuroscience field, which will be too complex to apply certain techniques from bifurcation theory directly. Hence, we introduce the notion of (local) topological equivalence to remedy this issue.

:::{#def-topological-equivalence}
##### Topological Equivalence

A dynamical system $\obj D_1 = \set{\timeSet, \R^n, \evolOp^t}$ is said to be *topologically equivalent* to a dynamical system $\obj D_2 = \set{\timeSet, \R^n, \oper{\psi}^t}$, if there exists a *homeomorphism*[^homeomorphism] $\vi h: \R^n \to \R^n$, which maps orbits of system $\obj D_1$ to orbits of system $\obj D_2$, such that their orientation is kept. In such case, their phase portraits are called *(topologically) equivalent*.
:::

[^homeomorphism]: In the context of topology, a *homeomorphism* (also called a *bicontinuous function*) is a bijective and continuous function, such that its inverse is also continuous.

:::{#def-local-topological-equivalence}
##### Local Topological Equivalence

A dynamical system $\obj D_1 = \set{\timeSet, \R^n, \evolOp^t}$ is said to be *locally topologically equivalent* in the neighborhood of its equilibrium $\vi x^*$ to a dynamical system $\obj D_2 = \set{\timeSet, \R^n, \oper{\psi}^t}$ in the neighborhood of its equilibrium $\vi y^*$, if there exists a *homeomorphism* $\vi h: \R^n \to \R^n$, such that

1. $\vi h$ is defined on a (small) neighborhood $\neigh{\vi x^*} \subset \R^n$,
2. satisfies $\vi y^* = \vi h(\vi x^*)$ and
3. maps orbits of dynamical system $\obj D_1$ in the neighborhood $\neigh{\vi x_0}$ to orbits of system $\obj D_2$ in the neighborhood $\neigh{\vi y^*}$, such that their orientation is kept.
:::

### Continuous-time Autonomous Systems

:::{#def-autonomous-ode-system}
An *autonomous system of (ordinary) differential equations* is a system of form
$$
\dvi x = \vi f(\vi x),
$$ {#eq-autonomous-ode-system}
where $\vi x \in \stateSpace = \R^n$ and a vector-valued function $\vi f: \R^n \to \R^n$ is sufficiently smooth. The symbol $\dvi x$ denotes a derivative of $\vi x(t)$ with respect to time $t \in \timeSet = \R$.

The system of ODEs ([-@eq-autonomous-ode-system]) induces a *continuous-time autonomous dynamical system*.
:::

:::{#thm-lyapunov-ode}
##### Lyapunov

Consider a dynamical system ([-@eq-autonomous-ode-system]) with an equilibrium $\vi x^*$. Let
$$
\Jacobi^* = \jacobi \vi f(\vi x^*) = \mtr{
	\pDeriv {f_1} {x_1} (\vi x^*) & \pDeriv {f_1} {x_2} (\vi x^*) & \dots & \pDeriv {f_1} {x_n} (\vi x^*) \\
	\pDeriv {f_2} {x_1} (\vi x^*) & \pDeriv {f_2} {x_2} (\vi x^*) & \dots & \pDeriv {f_2} {x_n} (\vi x^*) \\
	\vdots & \vdots & \ddots & \vdots \\
	\pDeriv {f_n} {x_1} (\vi x^*) & \pDeriv {f_n} {x_2} (\vi x^*) & \dots & \pDeriv {f_n} {x_n} (\vi x^*)
}
$$
denote a Jacobian matrix evaluated at $\vi x^*$. Then $\vi x^*$ is *stable*, if all eigenvalues $\lmbd_i$, where $i \in \oneToN{n}$^[For conciseness, we use the following notation $\oneToN{n} := \set{1, \dots, n}.$], of the matrix $\Jacobi^*$ satisfy $\reOf{\lmbd_i} < 0$.
:::

:::{.proof}
See @Chicone2006, page 160, or @Perko2001, page 185.
:::

:::{#def-hyperbolic-equilibrium-cont}
##### Hyperbolic Equilibrium

An equilibrium $\vi x^*$ of the system ([-@eq-autonomous-ode-system]) is called *hyperbolic*, if none of the eigenvalues corresponding to the Jacobian matrix $\Jacobi^* = \jacobi \vi f(\vi x^*)$ lies on the imaginary axis.
:::

:::{#thm-grobman-hartman-cont}
##### Grobman-Hartman

The system ([-@eq-autonomous-ode-system]) in a neighborhood of its *hyperbolic* equilibrium $\vi x^*$ is *locally topologically equivalent*, in the sense of @def-local-topological-equivalence, to its linearization
$$
\dvi x = \jacobi \vi f(\vi x^*) \vi x.
$$ {#eq-linearization}
:::

:::{.proof}
See @Chicone2006, page 306, or @Perko2001, page 120.
:::

#### Lyapunov's Direct Method

:::{#def-lpd-function}
A function $V: \R^n \to \R$ is called *locally positive-definite (LPD)* at $\vi x^*$, if the following holds:

1. $V(\vi x^*) = 0$,
2. $V(\vi x) > 0$, $\vi x \in \neigh{\vi x^*} \setminus \set{\vi x^*}$ for some neighborhood $\neigh{\vi x^*}$.

If only $V(\vi x) \geq 0$ holds on a neighborhood $\neigh{\vi x^*}$, then the function is called *locally positive semi-definite (LPSD)*. Analogously, we can define a *locally negative (semi-)definite* function.
:::

:::{#def-lyapunov-function}
###### Lyapunov Function

Let $\vi \vf(t; \vi x_0)$ be a solution of the system ([-@eq-autonomous-ode-system]) together with the initial $\vi x(0) = \vi x_0$. A function $V: \R^n \to \R$ is called *Lyapunov* at $\vi x^*$, if $V$ is locally positive definite and also $\forall \vi x_0 \in \neigh{\vi x^*}$ is the function $V \circ \vi \vf(t; \vi x_0)$ *non-increasing* for all $t > 0$.

Moreover, the function $V$ is called *strictly Lyapunov* if $V \circ \vi \vf(t; \vi x_0)$ is *(strictly) decreasing* for all $t > 0$.
:::

::: {.callout-note #nte-lyapunov-function}
##### Monotonicity of $V \circ \vi \vf(t; \vi x_0)$

Equivalently to requiring a non-increasing $V \circ \vi \vf(t; \vi x_0)$, one can instead demand the *derivatives with respect to the trajectories* of $V$, i.e. $\dot V(\vi x(t))$, to be non-positive. In other words, the *derivative w.r.t. the trajectories* $\dot V$ must be *locally negative semi-definite*.
:::

:::{#thm-lyapunov-stability-theorem}
##### Lyapunov's Direct Method

If $\vi x^*$ is an equilibrium of the system ([-@eq-autonomous-ode-system]) and $V$ is a *Lyapunov* function for the system at $\vi x^*$, then $\vi x^*$ is *Lyapunov stable*. If, in addition, $V$ is a *strict Lyapunov* function, then $\vi x^*$ is *stable*.
:::

:::{.proof}
See @Chicone2006, page 24.
:::

### Discrete Dynamical Systems

:::{#def-autonomous-difference-system}

An *autonomous system of difference equations* is a system of form
$$
\vi x \mapsto \vi f(\vi x) \quad \iff \quad \vi x_{m+1} = \vi f(\vi x_m),
$$ {#eq-autonomous-difference-sys}
where $\vi x, \vi x_m \in \stateSpace = \R^n$ and the function $\vi f : \R^n \to \R^n$ is sufficiently smooth.

The system ([-@eq-autonomous-difference-sys]) induces a *discrete-time autonomous dynamical system*.
:::

:::{#thm-lyapunov-differences}
##### Lyapunov, analogous to @thm-lyapunov-ode

Consider a dynamical system ([-@eq-autonomous-difference-sys]) with a fixed point $\vi x^*$. Let $\Jacobi^* = \jacobi \vi f(\vi x^*)$ denote the Jacobian matrix evaluated at $\vi x^*$. Then $\vi x^*$ is stable, if all eigenvalues^[Eigenvalues of fixed points of discrete-time dynamical systems are often called *multipliers*, see @Sevcik2021.] $\lambda_i$, where $i \in \oneToN{n}$, of the matrix $\Jacobi^*$ satisfy $\absval{\lambda_i} < 1$.
:::

:::{.proof}
See @Elaydi2005, page 222.
:::

:::{#def-hyperbolic-equilibrium-discrete}
##### Hyperbolic fixed point

A fixed point $\vi x^*$ of the system ([-@eq-autonomous-difference-sys]) is called **hyperbolic**, if none of the eigenvalues corresponding to the Jacobian matrix $\Jacobi^* = \jacobi \vi f(\vi x^*)$ has unit magnitude.
:::

:::{#thm-grobman-hartman-discrete}
##### Grobman-Hartman, analogous to @thm-grobman-hartman-cont

The system ([-@eq-autonomous-difference-sys]) is locally topologically equivalent in the neighborhood of its *hyperbolic* fixed point $\vi x^*$ to its linearization
$$
\vi x \mapsto \jacobi \vi f(\vi x^*) \vi x.
$$
:::

:::{.proof}
See @Chicone2006, page 311.
:::

:::{#exm-fixed-points-2d}
##### Fixed points of two-dimensional discrete-time dynamical system

As an example, consider a two-dimensional discrete-time dynamical system
$$
\vi x_{m+1} = \vi f(\vi x_{m}),
$$ {#eq-2d-discrete-dyn-sys}
where $\vi x_m = (x_{m, 1}, x_{m, 2})\Tr$ and $\vi f : \R^2 \to \R^2$ is smooth. Moreover, let us assume there exists a *hyperbolic equilibrium* $\vi x^* = \vi f(\vi x^*)$ of the system ([-@eq-2d-discrete-dyn-sys]) and let $\Jacobi^* = \jacobi \vi f(\vi x^*)$ denote the corresponding Jacobian matrix evaluated at $\vi x^*$. Then $\Jacobi^*$ has two eigenvalues $\lambda_1, \lambda_2$, which satisfy
$$
\det \brackets{\Jacobi^* - \lambda \ident_2} = \lambda^2 - \trace \Jacobi^* \lambda + \det \Jacobi^*.
$$
Here, $I_2$ corresponds to a 2-by-2 identity matrix, $\trace \Jacobi^* = \lambda_1 + \lambda_2$  is the trace of the  determinant and finally, $\det \Jacobi^* = \lambda_1 \lambda_2$ denotes the determinant of $\Jacobi^*$.

On a different note, in the case of a linear continuous-time dynamical system, i.e.
$$
\dvi y = \vi A \vi y,
$$
where $\vi y \in \R^n$ and $\vi A \in \R^{n\times n}$, with an equilibrium $\vi y^*$ we can partition the state-space into disjoint linear (vector) subspaces:

- *stable subspace* $\obj{E}^s = \Span{\vi v^1, \dots, \vi v^{n_{-}}}$ of dimension $n_{-}$, where $\vi v^1, \dots, \vi v^{n_{-}}$ are the eigenvectors of $\vi A$ corresponding to eigenvalues with *negative* real parts;
- *unstable subspace* $\obj{E}^u = \Span{\vi u^1, \dots, \vi u^{n_{+}}}$ of dimension $n_{+}$, where $\vi u^1, \dots, \vi u^{n_{+}}$ are the eigenvectors of $\vi A$ corresponding to eigenvalues with *positive* real parts;
- *central subspace* $\obj{E}^c = \Span{\vi w^1, \dots, \vi w^{n_0}}$ of dimension $n_{0}$, where $\vi w^1, \dots, \vi w^{n_0}$ are the eigenvectors of $\vi A$ corresponding to *strictly imaginary* eigenvalues, i.e. eigenvalues with zero real part.

Then it holds that $n_{-} + n_{+} + n_0 = n$. Similarly, for linear discrete-time dynamical systems, one can perform an equivalent partitioning, such that $\obj{E}^s$ is spanned by eigenvectors corresponding to eigenvalues *lying inside the unit circle* (on the imaginary plane). Furthermore, $\obj{E}^u$ and $\obj{E}^c$ can be defined for discrete-time dynamical systems analogously.

By @thm-grobman-hartman-discrete, we know that the system ([-@eq-2d-discrete-dyn-sys]) is locally topologically equivalent to its linearization in a neighborhood of its hyperbolic fixed point $\vi x^*$. Interestingly, we can classify the said fixed point based on the number of stable (and unstable) eigenvectors of the corresponding $\Jacobi^*$, i.e. the classification is based on the dimensions of $\obj E^s$, $\obj E^u$ and $\obj E^c$ of the partitioning of the state-space per linearization.

A fixed point is classified as a *sink*, when both eigenvalues are real and stable. Similarly, it is called a *spiral sink* if both eigenvalues are stable and complex. Should one eigenvalue be stable and the other unstable, the resulting fixed point is a *saddle*. Finally, an equilibrium is a *source*, resp. *spiral source*, when both eigenvalues are unstable and *real*, resp. *complex*. For an overview, see @fig-2d-discrete-dynamical-system.

```{julia}
#| fig-cap: "Orbits near different equilibria of a linear discrete-time dynamical system (time flows from blue to red)."
#| label: fig-2d-discrete-dynamical-system
#| tags: 
#|   - show-in-pdf

function integrate(A, x, n)
	X = similar(x, n, 2)
	X[1, :] = x
	for i = 2:n
		X[i, :] = A*X[i - 1, :]
	end
	return X
end

fig = Figure(size = (1000, 200), backgroundcolor=:transparent)

x0 = [1.0, 1.0]
x_eq = [0.01, 0.01]
n = 12

ax = Axis(fig[1,1], title="sink")
hidedecorations!(ax)
scatterlines!(ax, integrate([0.5 0; 0 0.25], x0, n), colormap=:Zissou1, color=1:n)

ax = Axis(fig[1,2], title="spiral sink")
hidedecorations!(ax)
scatterlines!(ax, integrate([0.5 0.25; -0.25 0.5], x0, n), colormap=:Zissou1, color=1:n)

ax = Axis(fig[1,3], title="saddle")
hidedecorations!(ax)
scatterlines!(ax, integrate([1.25 0; 0 0.25], x0, n), colormap=:Zissou1, color=1:n)
scatterlines!(ax, integrate([1.25 0; 0 0.25], x0 .* [-1.0, 1.0], n), colormap=:Zissou1, color=1:n)

ax = Axis(fig[1,4], title="source")
hidedecorations!(ax)
scatterlines!(ax, integrate([1.5 0; 0 1.25], x_eq, n), colormap=:Zissou1, color=1:n)

ax = Axis(fig[1,5], title="spiral source")
hidedecorations!(ax)
scatterlines!(ax, integrate([1.5 0.75; -0.75 1.5], x_eq, n), colormap=:Zissou1, color=1:n)

fig
```
<!-- TODO: Check color direction in caption correct -->
:::

For completeness sake, a classical result from theory of ODEs concerning the existence, uniqueness and smooth dependence on the initial conditions of the solution for a given ODE.

:::{#thm-exists-unique-smooth-ode-solution}
##### Existence, uniqueness and smooth dependence

Consider a system of ordinary differential equations
$$
\dvi x = \vi f(\vi x), \vi x \in \R,
$$
where $\vi f: \R^n \to \R^n$ is smooth in an open region $U \subset \R^n$. Then there is a unique function $\vi x = \vi x(t, \vi x_0)$, $\vi x : \R^1 \times \R^n \to \R^n$, that is smooth in $(t,x)$, and satisfies, for each $\vi x_0 \in U$, the following conditions:

1. $\vi x(0, \vi x_0) = \vi x_0$;
2. there is an interval $\timeInt = (-\delta_1, \delta_2)$, where $\delta_{1,2} = \delta_{1,2}(\vi x_0) > 0$, such that, for all $t \in \timeInt$,
	$$
	\vi y(t) = \vi x(t, \vi x_0) \in U,
	$$
	and
	$$
	\dvi y(t) = \vi f(\vi y(t)).
	$$
:::

:::{.proof}
See @Hartman2002, page 94.
:::


### Poincaré map

The study of continuous-time dynamical systems naturally leads to discrete-time dynamical systems, be it via sampling the continuous orbit at discrete times, e.g. separated by $\Delta t$ which induces a *time-shift map*. Another way to obtain a discrete-time dynamical system from a continuous-time one is through a so-called *Poincaré map*.

Consider a continuous-time dynamical system of form
$$
\dvi x = \vi f(\vi x), \quad \vi x \in \R^n,
$$ {#eq-poincare-map-system}
where $\vi f$ is smooth and assume that ([-@eq-poincare-map-system]) has a periodic orbit $L_0$. Let $\vi x_0$ be a point on $L_0$ and denote $\crossSection$ the *cross-section* to the cycle at this point, see @fig-poincare-map.

![Poincaré map corresponding to the system ([-@eq-poincare-map-system]), the cycle $L_0$ and its point $\vi x_0$.](diagrams/poincare_maps.drawio.svg){#fig-poincare-map .final}

The cross-section $\crossSection$ is a smooth hypersurface of dimension $n-1$ (thus we say $\codim \crossSection = 1$, i.e. the cross-section hypersurface $\crossSection$ is of "codimension" one), which intersects $L_0$ at a nonzero angle. The nonzero angle requirement is called the *transversality* condition, which effectively dictates that the hypersurface is not parallel to the through-going trajectories, thus the trajectories truly intersect the cross-section $\crossSection$.

Consider now orbits of ([-@eq-poincare-map-system]) near the cycle $L_0$ and recall that the cycle $L_0$ itself is an orbit which starts at point $\vi x_0$ on $\crossSection$ and returns to the same point on $\crossSection$. As the @thm-exists-unique-smooth-ode-solution guarantees the solution of ([-@eq-poincare-map-system]) depend smoothly on its initial condition, an orbit starting at $\vi x \in \crossSection$ sufficiently close to $\vi x_0$ will transversally intersect the hypersurface $\crossSection$ at some other point $\tilde{\vi x}$ near $\vi x_0$. Therefore, this induces a map $\vi P: \crossSection \to \crossSection$,
$$
\vi x \mapsto \tilde{\vi x} = \vi P(\vi x).
$$

:::{#def-poincare-map}
##### Poincaré map

The map $\vi P$ defined above is called a *Poincaré map* associated with the cycle $L_0$.
:::

Similarly, we can characterize the Poincaré map $\vi P$ using a local coordinates $\vi \xi = (\xi_1, \dots, \xi_{n - 1})$ on $\crossSection$, such that the choice $\vi \xi = \vi 0$ corresponds to $\vi x_0$. Then the Poincaré map can be locally defined as a function $\vi P: \R^{n - 1} \to \R^{n - 1}$, which maps $\vi \xi$ corresponding to $\vi x$ to $\tilde{\vi \xi}$ corresponding to $\tilde {\vi x}$, i.e.
$$
\vi P(\vi \xi) = \tilde{\vi \xi}.
$$

In other words, the Poincaré map $\vi P$ prescribes a *discrete-time dynamical system* on the hypersurface $\crossSection$. Its origin $\vi \xi = \vi 0$ is a fixed point of this mapping. To our advantage, the stability of the underlying cycle $L_0$ is then equivalent to the stability of the fixed point $\vi \xi_0 = \vi 0$. By @thm-lyapunov-differences, we know the cycle is thus stable if all eigenvalues (also called *multipliers*) $\mu_1, \dots, \mu_{n - 1}$ of the $(n - 1) \times (n - 1)$ Jacobian matrix of $\vi P$,
$$
\Jacobi_{\vi P} = \jacobi_{\vi \xi} \vi P(\vi \xi_0),
$$
are located inside the unit circle $\norm{\vi \mu} = 1$. The Poincaré map will throughout this thesis paint itself a powerful tool in the bifurcation analysis of dynamical systems, and the following lemma hints at its usefulness.

:::{#lem-poincaré-map}
The multipliers $\mu_1, \dots, \mu_{n - 1}$ of the Jacobian matrix $\Jacobi_{\vi P}$ of the Poincaré map $\vi P$ associated with a cycle $L_0$ are independent of the point $\vi x_0$ on $L_0$, the cross-section $\crossSection$, and local coordinates on it.
:::

:::{.proof}
See @Kuznetsov2023, page 27.
:::

Consider now the cycle $L_0$ and let $\vi x^0(t)$ denote its corresponding periodic solution of ([-@eq-poincare-map-system]) with the period $T_0$, i.e. $\vi x^0(t + T_0) = \vi x^0(t)$. Then any solution $\vi x(t)$ of ([-@eq-poincare-map-system]) can be written as
$$
\vi x(t) = \vi x^0(t) + \vi u(t),
$$
where $\vi u(t)$ stands for the deviation of the solution from the referential periodic solution. Then,
\begin{align*}
\dvi u(t) &= \dvi x(t) - \dvi x^0(t) \\
	&= \vi f(\vi x^0(t) + \vi u(t))  - \vi f(\vi x^0(t)) \\
	&= \Jacobi(t) \vi u(t) + O(\norm{\vi u(t)}^2).
\end{align*}
Omitting $O(\norm{\vi u(t)}^2)$ terms gives us a linear $T_0$-periodic system
$$
\dvi u = \Jacobi(t) \vi u, \quad \vi u \in \R^n,
$$ {#eq-variational-about-cycle}
where $\Jacobi(t) = \jacobi_{\vi x} \vi f(\vi x^0(t))$, and $\Jacobi(t + T_0) = \Jacobi(t)$.

:::{#def-variational-equation-about-cycle}
System ([-@eq-variational-about-cycle]) is called the *variational equation* about the cycle $L_0$.
:::

As the variational equation describes the evolution of perturbations in the proximity of the cycle $L_0$, naturally its stability depends on the properties of the variational equation.

:::{#def-monodromy-matrix}
The time-dependent matrix $\vi M(t)$ is called the *fundamental matrix solution* of ([-@eq-poincare-map-system]) if it satisfies
$$
\dvi M = \Jacobi(t) \vi M,
$$
with the initial condition $\vi M(0) = \ident_n$. The matrix $\vi M(T_0)$ is called a **monodromy matrix** of the cycle $L_0$.
:::

:::{#thm-floquet-exponents}
##### Floquet exponents

The monodromy matrix $\vi M(T_0)$ has eigenvalues (called *Floquet exponents* or *multipliers*)
$$
1, \mu_1, \dots, \mu_{n - 1},
$$
where $\mu_i$ are the multiplier of the Poincaré map $\vi P$ associated with the cycle $L_0$, see @lem-poincaré-map.
:::

:::{.proof}
See @Kuznetsov2023, page 30, for a sketch of the proof.
:::

## Semidynamical Systems

We have already shown in ([-@eq-ode-verhulst]) that one can define a continuous-time dynamical system with (a system of) differential equations. Most often, these come in form of a system of $n$ autonomous ordinary differential equations, ODEs for short, i.e. for a state space $\stateSpace = \R^n$ we have
$$
\dvi x = \vi f(\vi x),
$$ {#eq-dyn-sys-ode}
where the vector-valued function $\vi f: \R^n \to \R^n$ is *sufficiently smooth*. The function $\vi f$ is called a *vector field*, as it maps a vector $\vi f(\vi x)$ to each point $\vi x$ of the state space.

<!-- TODO: Add a vector field illustration figure -->

Analogously, one could use a system of **delay** differential equations, e.g. ([-@eq-dde-verhulst]), to implicitly define an autonomous dynamical system, see @Feng2019, @Nelson2013 and @Richard2003. In general, delay differential equations (DDEs) are differential equations whose solution depends on a certain past history of the system, as opposed to ODEs where the history is a singular starting time $t = t_0$. Hence, the DDEs are a class of *functional differential equations*, where the state is a function on the relevant past history. As an example, for ([-@eq-dde-verhulst]) the past history, which is required to be known, is $[t-\tau, t]$ at any point in time $t \in \timeSet$. It also implies that the state space is *infinite-dimensional* for DDEs.

For the purpose of this thesis, we shall consider primarily an **autonomous discrete-delay differential equation** with **constant** delays $\tau_1, \dots, \tau_k$ of form
$$
\dvi x(t) = \vi f(\vi x(t), \vi x(t - \tau_1), \dots, \vi x(t - \tau_k)).
$$ {#eq-discrete-dde}
Relatively commonly also appear *continuous-delay differential equation*
$$
\dot x(t) = \vi f\brackets{t, x(t), \int_0^{\infty} x(t - \tau) g(\tau) \dd \tau},
$$
where $x(t)$ is for simplicity a scalar state, or *state-dependent DDEs*, see @BifurcationKit, e.g. the Humphries model, see @RHumphries2012,
$$
\dot x(t) = - \gamma x(t) - \kappa_1 x(t - a_1 - cx(t)) - \kappa_2 x(t - a_2 - cx(t)).
$$ {#eq-humphries}

#### Delayed Differential Dynamics {#sec-delayed-differential-dynamics}

Let us denote by $\contf {[a,b], \R^n} 0$ the space of all continuous functions from $[a,b]$ to $\R^n$. Moreover, let $\Contf 1$ be the set of all *continuously differentiable* functions and $\histories {\tau} := \contf {[-\tau, 0], \R^n} 0$ be the set of all possible histories for a positive constant $\tau$ (and the time $0$).

We shall consider a class of dynamical systems which are governed by a system of DDEs of type ([-@eq-discrete-dde]), i.e. *autonomous discrete-constant-delay differential equations*
$$
\begin{cases}
	\dvi x(t) = \vi f(\vi x(t), \vi x(t - \tau_1), \dots, \vi x(t - \tau_k)), & t \in [0, \infty) \\
	\vi x(t) = \vi \phi(t), & t \in [\tau_k, 0],
\end{cases}
$$ {#eq-delayed-diff-dynamics}
where $\vi x \in \R^n$ is the time-dependent state vector. The constant discrete delays are assumed to be ordered as $\tau_k > \dots > \tau_1 > 0$, and the initial states are specified by a vector-valued **history** function $\vi \phi(t) \in \histories {\tau_k}$.

If $\vi f \in \contf {\R^{(k+1)n}, \R^n} 1$ is a Lipschitz-continuous function, then the system ([-@eq-delayed-diff-dynamics]) has a unique solution, i.e. *orbit*, from a given initial condition $\vi \phi \in \histories {\tau_k}$, denoted as $\Orbit{\vi \phi}: [-\tau_k, \infty) \to \R^n$.

<!-- TODO: Maybe add Jacobian notation with respect to various delays -->
<!-- TODO: Improve DDE section -->