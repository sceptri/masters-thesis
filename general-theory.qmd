---
engine: julia
---

:::{.content-visible when-format="pdf"}
\HeaderNumbered
:::


:::{.hidden}
{{< include mathematics.qmd >}}

```{julia}
#| echo: false
#| output: false

using Pkg
Pkg.activate(".")
```
:::

:::{.content-hidden unless-format="html"}
```{julia}
#| echo: false
#| output: false

using WGLMakie
WGLMakie.activate!()
```
:::

:::{.content-hidden when-format="html"}
```{julia}
#| echo: false
#| output: false

using CairoMakie
CairoMakie.activate!()
```
:::

# Mathematics Behind Dynamics {#sec-general-theory}

We have motivated the entire thesis with the usefulness of the knowledge and of the understanding of synchronization in neuroscience. However, we will not describe any experiments performed on real couples of neurons in a lab. Instead, we shall deal with the mathematical abstraction for the studied object, e.g. the coupled neurons.

This abstraction is typically called a (mathematical) model (of the reality). The model should, in theory, capture all the important characteristics of the underlying reality. If the state of the model causally evolves in time, e.g. a model of neuron starts spiking, we often use a *dynamical system* as the model. On the other hand, if the governing rules are noncausal due to the dependence on some past states of the system, the arising dynamical system becomes infinite dimensional. For better "mathematical ergonomics" we will define a *semidynamical system*, a special case of a dynamical system.

## A Primer on Dynamical Systems {#sec-dynamical-systems}

First and foremost, we will formally introduce the notion of a *dynamical system*, along with its properties. This section is mostly based on @Kuznetsov2023 and @Pribylova2021 in terms of the content. It should be noted the notation follows @Teschl2012, @Guo2013, @Saperstone1981 or @Smith2010 for better compatibility with semidynamical systems. Also, @Sevcik2021 was used as a valuable inspiration for the structure of this section.

:::{#def-dynamical-system}
**Dynamical system** (more precisely *deterministic dynamical system*) is a triple $(\timeSet, \stateSpace, \evolOp)$, where $(\timeSet, +, \leq)$, $\timeSet \subseteq \R$, is an ordered commutative semigroup with identity element $0$, $\stateSpace$ (called *state space*) is a metric space, and $\evolOp$ is a continuous^[The evolution map $\evolOp$ is continuous, if $t,s \in \timeSet$, $x \in \stateSpace$ and if $\set{(t_n, s_n)}_n$ is a sequence in $\timeSet \times \timeSet$ and $\Seqnc {x_n} n {}$ is a sequence in $\stateSpace$ such that $(t_n, s_n) \to (t,s)$ and $x_n \to x$, then $\evolOp(t_n, s_n, x_n) \to \evolOp(t,s,x)$.] evolution map
$$
\begin{aligned}
\evolOp : {} & \timeSet \times \timeSet \times \stateSpace & &\to & &\stateSpace \\
	& (t, s, x) &&\mapsto &&\evolOp(t, s, x),
\end{aligned}
$$ 
projecting a state $x$ from time $s$ to time $t$, which satisfies

1. (*deterministic property*): $\evolOp(s,s, x) = x$ for each $x \in \stateSpace$ and $s \in \timeSet$,
2. (*composition property*): $\evolOp(t,s,x) = \evolOp(t,r,\evolOp(r,s,x))$ for each $x \in \stateSpace$ and $t,r,s \in \timeSet$.

If $(\timeSet, +)$ is a group, we will speak of an **invertible dynamical system**.
:::

For simplicity, we shall assume the commutative monoid $(\timeSet, +)$ is *cancellative*, i.e., $a + x = b + x \implies a = b$ for each $a,b,x \in \timeSet$. Then it can be embedded in a Grothendieck group $\timeSet_G$, see @WikiGrothendieckGroup.

:::{#def-autonomous-dynamical-system}
**Autonomous dynamical system** is a dynamical system such that the *autonomous property*,
$$
\evolOp(t, s, x) = \evolOp(t + r, s + r, x)
$$ {#eq-autonomous-property}
for each $x \in \stateSpace$, $t,s \in \timeSet$, and $r \in \timeSet_G$, is fulfilled. 
:::

::: {.callout-note #nte-autonomous-dyn-sys}
##### Evolution operator as monoid action

In the case of @def-autonomous-dynamical-system, we can always vanish the starting time by taking $r = -s$ in ([-@eq-autonomous-property]), which is ensured by $r \in \timeSet_G$. Then, by abuse of notation, we will write $\evolOp: \timeSet \times \stateSpace \to \stateSpace$. Moreover, the *composition* and *autonomous* properties combine into the *semigroup property*,
$$
\evolOp(t, \evolOp(s, x)) = \evolOp(t + s, x) \; \forall x \in \stateSpace, \forall t,s \in \timeSet,
$$
i.e., the map $\evolOp$ is a (left) monoid action of $(\timeSet, +)$ on $\stateSpace$. The operator $\evolOp$ is typically called *flow* of the dynamical system.
:::

In the @def-dynamical-system, the time set $\timeSet$ can take on various forms. In ecology, we often see a discrete $\timeSet = \Z$ or $\N_0$ representing a yearly interval between measurements of our system --- given this choice of $\timeSet$, we call the dynamical system **discrete**. 

On the other hand, in physics (and neuroscience) we typically employ $\timeSet = \R$ or $\R^+$ as we are concerned with even the shortest time intervals and associated changes --- corresponding systems are called **continuous** or **continuous-time** dynamical systems. Similarly, the exact choice of the state space $\stateSpace$ is dependent on the system in question, but typically we use $\R^n$, although we will also encounter infinite-dimensional state space.

The *deterministic* property in @def-dynamical-system guarantees the system does not abruptly change state. Should this condition be broken, we would call such system *stochastic*. Moreover, a common assumption that the "laws of nature" do not change in time restricts us to autonomous dynamical systems, which will be exclusively used in this thesis, where it is captured by the *semigroup* (or *autonomous*) property. In particular, dependence on past is permitted, but requires special attention, as we shall see in @sec-dynamical-systems-delays. If the system is *invertible*, the *(semi)group property* implies that the solution can be found both forward and backward in time.

Most often, a dynamical system is given implicitly by a *differential* or *difference* equation. For example, in population dynamics, one of the earliest models, the *Verhulst model of population*[^verhulst], can prescribed by an ordinary differential equation (ODE)
$$
\dot{x}(t) = \deriv {x(t)} t = x(t) \cdot r_0 \cdot \brackets{1 - \frac {x(t)} K},
$$ {#eq-ode-verhulst}
or a *difference equation* (although these two models are *not* equivalent)
$$
x(t+1) = x(t) \cdot r_0 \cdot \brackets{1 - \frac {x(t)} K}.
$$ {#eq-difference-verhulst}

[^verhulst]: The equation ([-@eq-ode-verhulst]) describes the [Verhulst](https://en.wikipedia.org/wiki/Pierre_Fran%C3%A7ois_Verhulst) model of a population (and its growth, characterized by $r_0$) in some closed environment with some finite capacity (controlled by $K$).

### Basic Concepts {#sec-basic-concepts}

In this section, we shall introduce basic concepts regarding dynamical systems including, but not limited to, notions of certain special solutions and their stability. Little comment beside the definitions themselves will be provided, as an interested reader can find much more in @Pribylova2021, @Hartman2002 or @Kuznetsov2023.

:::{#def-orbit}
##### Orbit

An *orbit (trajectory)* with an *initial point* $x_0 \in \stateSpace$ is an ordered subset of the state space $\stateSpace$,
$$
\Orbit{x_0} = \set{x \in \stateSpace \divider x = \evolOp(t, x_0), \forall t \in \timeSet \text{ such that } \evolOp(t, x_0) \text{ is defined}}
$$

In the case of a continuous dynamical system, the orbits are *oriented curves* in the state space. For a discrete dynamical systems, they become sequences of points in $\stateSpace$.
:::

:::{#def-phase-portrait}
##### Phase portrait
A *phase portrait* of a dynamical system is a partitioning of the state space into trajectories.
:::

:::{#def-equilibrium}
##### Equilibrium

A point $x^* \in \stateSpace$ is called an *equilibrium* (fixed point) if $\evolOp(t, x^*) = x^*$ for all $t \in \timeSet$.
:::

:::{#def-cycle}
##### Cycle

A *cycle* is a periodic orbit, namely a non-equilibrium orbit $L$, such that each point $x_0 \in L$ satisfies $\evolOp(t + T, x_0) = \evolOp(t, x_0)$ with some $T > 0$, for all $t \in \timeSet$. The smallest admissible $T$ is called the *period* of the cycle $L$.
:::

:::{#def-invariant-set}
##### Invariant set

An *invariant set* of a dynamical system $(\timeSet, \stateSpace, \evolOp)$ is a subset $\obj S \subset \stateSpace$ which satisfies
$$
x \in \obj{S} \implies \evolOp(t, x) \in \obj{S} \; \forall t \in \timeSet.
$$
:::

:::{#def-limit-point}
##### $\omega$-limit and $\alpha$-limit point

A point $x_* \in \stateSpace$ is called an *$\omega$-limit point* (resp. $\alpha$-limit point) of the orbit $\Orbit{x_0}$ starting at $x_0 \in \stateSpace$ if their exists a sequence of times $\seqnc{t}{k}{1}{\infty} \subseteq \timeSet$ with $t_k \to \infty$ (resp. $t_k \to - \infty$)^[For a careful reader, let us note we assume $t_k \to \infty$ is well-defined, though it might restrict full generality of @def-dynamical-system.], such that
$$
\evolOp(t_k, x_0) \onBottom{\longrightarrow}{k \to \infty} x_*.
$$
:::

:::{#def-limit-set}
##### $\omega$-limit and $\alpha$-limit set

A set $\obj \Omega(\Orbit{x_0})$ of all $\omega$-limit points of the orbit $\Orbit{x_0}$, see @def-limit-point, is called an $\omega$-limit set. Similarly, a set $\obj A(\Orbit{x_0})$ of all $\alpha$-limit points of the orbit $\Orbit{x_0}$ is called an $\alpha$-limit set.

Lastly, a set $\limitSet(\Orbit{x_0}) = \obj \Omega(\Orbit{x_0}) \cup \obj A(\Orbit{x_0})$ of all limit points of the orbit $\Orbit{x_0}$ is called its *limit set*.
:::

<!--  FIXME: Add, but I am not sure of the translation
:::{#def-limit-invariant-loop}
##### Limit invariant loop

::: -->

:::{#def-limit-cycle}
##### Limit cycle

A cycle of a continuous-time dynamical system, in a neighborhood of which there are no other cycles, is called a *limit cycle*.
:::

::: {.callout-note #nte-limit-cycle}
##### Equivalent definition of a limit cycle

Equivalently to @def-limit-cycle, one can define a *limit cycle* as a cycle, which is the limit set, see @def-limit-set, of orbits in its neighborhood.
:::

<!-- TODO: Add citations (use files/, Kuznetsov...) -->

:::{#def-invariant-set-stable}

An invariant set $S_0$ is called 

1. **Lyapunov stable** if for any sufficiently small neighborhood $U \supset S_0$ there exists a neighborhood $V \supset S_0$ such that $\evolOp(t, x) \in U$ for all $x \in V$ and all $t > 0$;
2. **asymptotically stable** there exists a neighborhood $U_0 \supset S_0$ such that $\evolOp(t, x) \to S_0$ for all $x \in U_0$, as $t \to +\infty$;
3. **stable** if it is both *Lyapunov* and *asymptotically stable*;
4. **unstable** if it is not *stable*.
:::

Stable invariant set is called an *attractor*, whereas if the invariant set is unstable it is called a *repeller*.

#### Topologically Equivalent Dynamical Systems

<!-- TODO: Add refs to section -->
So far, we have described dynamical systems mainly in general terms. Later, we will get to concrete examples of dynamical systems, primarily from the neuroscience field, which will be too complex to apply certain techniques from bifurcation theory directly. Hence, we introduce the notion of (local) topological equivalence to remedy this issue.

:::{#def-topological-equivalence}
##### Topological equivalence

A dynamical system $\obj D_1 = (\timeSet, \R^n, \evolOp)$ is said to be *topologically equivalent* to a dynamical system $\obj D_2 = (\timeSet, \R^n, \oper{\psi})$, if there exists a *homeomorphism*[^homeomorphism] $\vi h: \R^n \to \R^n$, which maps orbits of system $\obj D_1$ to orbits of system $\obj D_2$, such that their orientation is kept. In such case, their phase portraits are called *(topologically) equivalent*.
:::

[^homeomorphism]: In the context of topology, a *homeomorphism* (also called a *bicontinuous function*) is a bijective and continuous function, such that its inverse is also continuous.

:::{#def-local-topological-equivalence}
##### Local topological equivalence

A dynamical system $\obj D_1 = (\timeSet, \R^n, \evolOp)$ is said to be *locally topologically equivalent* in the neighborhood of its equilibrium $\vi x^*$ to a dynamical system $\obj D_2 = (\timeSet, \R^n, \oper{\psi})$ in the neighborhood of its equilibrium $\vi y^*$, if there exists a *homeomorphism* $\vi h: \R^n \to \R^n$, such that

1. $\vi h$ is defined on a (small) neighborhood $\neigh{\vi x^*} \subset \R^n$,
2. satisfies $\vi y^* = \vi h(\vi x^*)$ and
3. maps orbits of dynamical system $\obj D_1$ in the neighborhood $\neigh{\vi x_0}$ to orbits of system $\obj D_2$ in the neighborhood $\neigh{\vi y^*}$, such that their orientation is kept.
:::

### Continuous-time Autonomous Systems

:::{#def-autonomous-ode-system}
An *autonomous system of (ordinary) differential equations* is a system of form
$$
\dvi x = \vi f(\vi x),
$$ {#eq-autonomous-ode-system}
where $\vi x \in \stateSpace = \R^n$ and a vector-valued function $\vi f: \R^n \to \R^n$ is sufficiently smooth. The symbol $\dvi x$ denotes a derivative of $\vi x(t)$ with respect to time $t \in \timeSet = \R$.
:::

It can be shown the system of ODEs ([-@eq-autonomous-ode-system]) induces an *invertible continuous-time dynamical system* if $\vi f$ is sufficiently smooth, see @Kuznetsov2023 (Theorem 1.4).

In ([-@eq-autonomous-ode-system]), we have given the ODE in explicit form, but, in general, it can also be defined by an implicit higher-order equation
$$
\vi F(\vi x, \dvi x, \ddot{\vi x}, \dots, \vi x^{(k)}) = \vi 0.
$$ {#eq-implicit-ode-system}
Such system can always be translated into a first-order system of equations
$$
\vi G(\vi y, \dvi y) = \vi 0
$$
and, if $\vi F$ (or $\vi G$ respectively) allows it, even to the explicit form ([-@eq-autonomous-ode-system]).

::: {.callout-tip #tip-ode-vector-field}
##### Vector field

The function $\vi f$ is called a *vector field*, as it maps a vector $\vi f(\vi x)$ to each point $\vi x$ of the state space. See @fig-vector-field for an example.
:::

```{julia}
#| label: fig-vector-field
#| fig-cap: Vector field (or a phase portrait) corresponding to the dynamical system $\dot{x} = -x, \dot{y} = 2y$.
#| width: 60%
fig = Figure(size=(450, 350))
ax = Axis(fig[1,1])
streamplot!(ax, (x,y) -> Point2f(-x, 2y), -2..4, -2..2, colormap=:Zissou1)

fig
```

:::{#thm-lyapunov-ode}
##### Lyapunov

Consider a dynamical system ([-@eq-autonomous-ode-system]) with an equilibrium $\vi x^*$. Let
$$
\Jacobi^* = \jacobi \vi f(\vi x^*) = \mtr{
	\pDeriv {f_1} {x_1} (\vi x^*) & \pDeriv {f_1} {x_2} (\vi x^*) & \dots & \pDeriv {f_1} {x_n} (\vi x^*) \\
	\pDeriv {f_2} {x_1} (\vi x^*) & \pDeriv {f_2} {x_2} (\vi x^*) & \dots & \pDeriv {f_2} {x_n} (\vi x^*) \\
	\vdots & \vdots & \ddots & \vdots \\
	\pDeriv {f_n} {x_1} (\vi x^*) & \pDeriv {f_n} {x_2} (\vi x^*) & \dots & \pDeriv {f_n} {x_n} (\vi x^*)
}
$$
denote a Jacobian matrix evaluated at $\vi x^*$. Then $\vi x^*$ is *stable*, if all eigenvalues $\lmbd_i$, where $i \in \oneToN{n}$^[For conciseness, we use the following notation $\oneToN{n} := \set{1, \dots, n}.$], of the matrix $\Jacobi^*$ satisfy $\reOf{\lmbd_i} < 0$.
:::

:::{.proof}
See @Chicone2006, page 160, or @Perko2001, page 185.
:::

:::{#def-hyperbolic-equilibrium-cont}
##### Hyperbolic equilibrium

An equilibrium $\vi x^*$ of the system ([-@eq-autonomous-ode-system]) is called *hyperbolic*, if none of the eigenvalues corresponding to the Jacobian matrix $\Jacobi^* = \jacobi \vi f(\vi x^*)$ lies on the imaginary axis.
:::

:::{#thm-grobman-hartman-cont}
##### Grobman-Hartman

The system ([-@eq-autonomous-ode-system]) in a neighborhood of its *hyperbolic* equilibrium $\vi x^*$ is *locally topologically equivalent*, in the sense of @def-local-topological-equivalence, to its linearization
$$
\dvi x = \jacobi \vi f(\vi x^*) \vi x.
$$ {#eq-linearization}
:::

:::{.proof}
See @Chicone2006, page 306, or @Perko2001, page 120.
:::

This theorem is very prominently used in conjunction with *linear* continuous-time dynamical systems, i.e.,
$$
\dvi y = \vi A \vi y,
$$
where $\vi y \in \R^n$ and $\vi A \in \R^{n\times n}$, with an equilibrium $\vi y^*$. Thus, we can partition the state-space into disjoint linear (vector) subspaces:

- *stable subspace* $\obj{E}^s = \Span{\vi v^1, \dots, \vi v^{n_{-}}}$ of dimension $n_{-}$, where $\vi v^1, \dots, \vi v^{n_{-}}$ are the eigenvectors of $\vi A$ corresponding to eigenvalues with *negative* real parts;
- *unstable subspace* $\obj{E}^u = \Span{\vi u^1, \dots, \vi u^{n_{+}}}$ of dimension $n_{+}$, where $\vi u^1, \dots, \vi u^{n_{+}}$ are the eigenvectors of $\vi A$ corresponding to eigenvalues with *positive* real parts;
- *center subspace* $\obj{E}^c = \Span{\vi w^1, \dots, \vi w^{n_0}}$ of dimension $n_{0}$, where $\vi w^1, \dots, \vi w^{n_0}$ are the eigenvectors of $\vi A$ corresponding to *strictly imaginary* eigenvalues, i.e., eigenvalues with zero real part.

Then it holds that $n_{-} + n_{+} + n_0 = n$. Similarly, for linear discrete-time dynamical systems, one can perform an equivalent partitioning, such that $\obj{E}^s$ is spanned by eigenvectors corresponding to eigenvalues *lying inside the unit circle* (on the imaginary plane), see @thm-grobman-hartman-discrete below. Furthermore, $\obj{E}^u$ and $\obj{E}^c$ can be defined for discrete-time dynamical systems analogously.

Moreover, by @thm-grobman-hartman-cont we know that these subspaces will be preserved in some neighborhood of the *hyperbolic* equilibrium of the nonlinear system ([-@eq-autonomous-ode-system]). Specifically, because the equilibrium is *hyperbolic*, $\obj{E}^c = \set{\vi 0}$.

#### Lyapunov's Direct Method

:::{#def-lpd-function}
A function $V: \R^n \to \R$ is called *locally positive-definite (LPD)* at $\vi x^*$, if the following holds:

1. $V(\vi x^*) = 0$,
2. $V(\vi x) > 0$, $\vi x \in \neigh{\vi x^*} \setminus \set{\vi x^*}$ for some neighborhood $\neigh{\vi x^*}$.

If only $V(\vi x) \geq 0$ holds on a neighborhood $\neigh{\vi x^*}$, then the function is called *locally positive semi-definite (LPSD)*. Analogously, we can define a *locally negative definite* and *semi-definite* functions.
:::

:::{#def-lyapunov-function}
###### Lyapunov function

Let $\vi \vf(t; \vi x_0)$ be a solution of the system ([-@eq-autonomous-ode-system]) together with the initial $\vi x(0) = \vi x_0$. A function $V: \R^n \to \R$ is called *Lyapunov* at $\vi x^*$, if $V$ is locally positive definite and also $\forall \vi x_0 \in \neigh{\vi x^*}$ is the function $V \circ \vi \vf(t; \vi x_0)$ *non-increasing* for all $t > 0$.

Moreover, the function $V$ is called *strictly Lyapunov* if $V \circ \vi \vf(t; \vi x_0)$ is *(strictly) decreasing* for all $t > 0$.
:::

::: {.callout-note #nte-lyapunov-function}
##### Monotonicity of $V \circ \vi \vf(t; \vi x_0)$

Equivalently to requiring a non-increasing $V \circ \vi \vf(t; \vi x_0)$, one can instead demand the *derivatives with respect to the trajectories* of $V$, i.e., $\dot V(\vi x(t))$, to be non-positive. In other words, the *derivative w.r.t. the trajectories* $\dot V$ must be *locally negative semi-definite*.
:::

:::{#thm-lyapunov-stability-theorem}
##### Lyapunov's direct method

If $\vi x^*$ is an equilibrium of the system ([-@eq-autonomous-ode-system]) and $V$ is a *Lyapunov* function for the system at $\vi x^*$, then $\vi x^*$ is *Lyapunov stable*. If, in addition, $V$ is a *strict Lyapunov* function, then $\vi x^*$ is *stable*.
:::

:::{.proof}
See @Chicone2006, page 24.
:::

### Discrete Dynamical Systems

:::{#def-autonomous-difference-system}

An *autonomous system of difference equations* is a system of form
$$
\vi x \mapsto \vi f(\vi x) \quad \iff \quad \vi x_{m+1} = \vi f(\vi x_m),
$$ {#eq-autonomous-difference-sys}
where $\vi x, \vi x_m \in \stateSpace = \R^n$ and the function $\vi f : \R^n \to \R^n$ is sufficiently smooth.

The system ([-@eq-autonomous-difference-sys]) induces a *discrete-time autonomous dynamical system*.
:::

:::{#thm-lyapunov-differences}
##### Lyapunov, analogous to @thm-lyapunov-ode

Consider a dynamical system ([-@eq-autonomous-difference-sys]) with a fixed point $\vi x^*$. Let $\Jacobi^* = \jacobi \vi f(\vi x^*)$ denote the Jacobian matrix evaluated at $\vi x^*$. Then $\vi x^*$ is stable, if all eigenvalues^[Eigenvalues of fixed points of discrete-time dynamical systems are often called *multipliers*, see @Sevcik2021.] $\lambda_i$, where $i \in \oneToN{n}$, of the matrix $\Jacobi^*$ satisfy $\absval{\lambda_i} < 1$.
:::

:::{.proof}
See @Elaydi2005, page 222.
:::

:::{#def-hyperbolic-equilibrium-discrete}
##### Hyperbolic fixed point

A fixed point $\vi x^*$ of the system ([-@eq-autonomous-difference-sys]) is called **hyperbolic**, if none of the eigenvalues corresponding to the Jacobian matrix $\Jacobi^* = \jacobi \vi f(\vi x^*)$ has unit magnitude.
:::

:::{#thm-grobman-hartman-discrete}
##### Grobman-Hartman, analogous to @thm-grobman-hartman-cont

The system ([-@eq-autonomous-difference-sys]) is locally topologically equivalent in the neighborhood of its *hyperbolic* fixed point $\vi x^*$ to its linearization
$$
\vi x \mapsto \jacobi \vi f(\vi x^*) \vi x.
$$
:::

:::{.proof}
See @Chicone2006, page 311.
:::

:::{#exm-fixed-points-2d}
##### Fixed points of two-dimensional discrete-time dynamical system

As an example, consider a two-dimensional discrete-time dynamical system
$$
\vi x_{m+1} = \vi f(\vi x_{m}),
$$ {#eq-2d-discrete-dyn-sys}
where $\vi x_m = (x_{m, 1}, x_{m, 2})\Tr$ and $\vi f : \R^2 \to \R^2$ is smooth. Moreover, let us assume there exists a *hyperbolic equilibrium* $\vi x^* = \vi f(\vi x^*)$ of the system ([-@eq-2d-discrete-dyn-sys]) and let $\Jacobi^* = \jacobi \vi f(\vi x^*)$ denote the corresponding Jacobian matrix evaluated at $\vi x^*$. Then $\Jacobi^*$ has two eigenvalues $\lambda_1, \lambda_2$, which satisfy
$$
\det \brackets{\Jacobi^* - \lambda \ident_2} = \lambda^2 - \trace \Jacobi^* \lambda + \det \Jacobi^*.
$$
Here, $I_2$ corresponds to a 2-by-2 identity matrix, $\trace \Jacobi^* = \lambda_1 + \lambda_2$  is the trace of the  determinant and finally, $\det \Jacobi^* = \lambda_1 \lambda_2$ denotes the determinant of $\Jacobi^*$.

By @thm-grobman-hartman-discrete, we know that the system ([-@eq-2d-discrete-dyn-sys]) is locally topologically equivalent to its linearization in a neighborhood of its hyperbolic fixed point $\vi x^*$. Interestingly, we can classify the said fixed point based on the number of stable (and unstable) eigenvectors of the corresponding $\Jacobi^*$, i.e., the classification is based on the dimensions of $\obj E^s$, $\obj E^u$ and $\obj E^c$ of the partitioning of the state-space per linearization.

A fixed point is classified as a *sink*, when both eigenvalues are real and stable. Similarly, it is called a *spiral sink* if both eigenvalues are stable and complex. Should one eigenvalue be stable and the other unstable, the resulting fixed point is a *saddle*. Finally, an equilibrium is a *source*, resp. *spiral source*, when both eigenvalues are unstable and *real*, resp. *complex*. For an overview, see @fig-2d-discrete-dynamical-system.

```{julia}
#| fig-cap: "Orbits near different equilibria of a linear discrete-time dynamical system (time flows from blue to red)."
#| label: fig-2d-discrete-dynamical-system
#| width: 95%

function integrate(A, x, n)
	X = similar(x, n, 2)
	X[1, :] = x
	for i = 2:n
		X[i, :] = A*X[i - 1, :]
	end
	return X
end

fig = Figure(size = (1000, 200), backgroundcolor=:transparent)

x0 = [1.0, 1.0]
x_eq = [0.01, 0.01]
n = 12

ax = Axis(fig[1,1], title="sink")
hidedecorations!(ax)
scatterlines!(ax, integrate([0.5 0; 0 0.25], x0, n), colormap=:Zissou1, color=1:n)

ax = Axis(fig[1,2], title="spiral sink")
hidedecorations!(ax)
scatterlines!(ax, integrate([0.5 0.25; -0.25 0.5], x0, n), colormap=:Zissou1, color=1:n)

ax = Axis(fig[1,3], title="saddle")
hidedecorations!(ax)
scatterlines!(ax, integrate([1.25 0; 0 0.25], x0, n), colormap=:Zissou1, color=1:n)
scatterlines!(ax, integrate([1.25 0; 0 0.25], x0 .* [-1.0, 1.0], n), colormap=:Zissou1, color=1:n)

ax = Axis(fig[1,4], title="source")
hidedecorations!(ax)
scatterlines!(ax, integrate([1.5 0; 0 1.25], x_eq, n), colormap=:Zissou1, color=1:n)

ax = Axis(fig[1,5], title="spiral source")
hidedecorations!(ax)
scatterlines!(ax, integrate([1.5 0.75; -0.75 1.5], x_eq, n), colormap=:Zissou1, color=1:n)

fig
```
<!-- TODO: Check color direction in caption correct -->
:::

For completeness sake, we give a classical result from theory of ODEs concerning the existence, uniqueness and smooth dependence on the initial conditions of the solution for a given ODE.

:::{#thm-exists-unique-smooth-ode-solution}
##### Existence, uniqueness and smooth dependence

Consider a system of ordinary differential equations
$$
\dvi x = \vi f(\vi x), \vi x \in \R,
$$
where $\vi f: \R^n \to \R^n$ is smooth in an open region $U \subset \R^n$. Then there is a unique function $\vi x = \vi x(t, \vi x_0)$, $\vi x : \R^1 \times \R^n \to \R^n$, that is smooth in $(t,x)$, and satisfies, for each $\vi x_0 \in U$, the following conditions:

1. $\vi x(0, \vi x_0) = \vi x_0$;
2. there is an interval $\timeInt = (-\delta_1, \delta_2)$, where $\delta_{1,2} = \delta_{1,2}(\vi x_0) > 0$, such that, for all $t \in \timeInt$,
	$$
	\vi y(t) = \vi x(t, \vi x_0) \in U,
	$$
	and
	$$
	\dvi y(t) = \vi f(\vi y(t)).
	$$
:::

:::{.proof}
See @Hartman2002, page 94.
:::


### Poincaré Map {#sec-poincare-map}

The study of continuous-time dynamical systems naturally leads to discrete-time dynamical systems, be it via sampling the continuous orbit at discrete times, e.g. separated by $\Delta t$ which induces a *time-shift map*. Another way to obtain a discrete-time dynamical system from a continuous-time one is through a so-called *Poincaré map*.

Consider a continuous-time dynamical system of form
$$
\dvi x = \vi f(\vi x), \quad \vi x \in \R^n,
$$ {#eq-poincare-map-system}
where $\vi f$ is smooth and assume that ([-@eq-poincare-map-system]) has a periodic orbit $L_0$. Let $\vi x_0$ be a point on $L_0$ and denote $\crossSection$ the *cross-section* to the cycle at this point, see @fig-poincare-map.

![Poincaré map corresponding to the system ([-@eq-poincare-map-system]), the cycle $L_0$ and its point $\vi x_0$.](diagrams/poincare_maps.drawio.svg){#fig-poincare-map .final}

The cross-section $\crossSection$ is a smooth hypersurface of dimension $n-1$ (thus we say $\codim \crossSection = 1$, i.e., the cross-section hypersurface $\crossSection$ is of "codimension" one), which intersects $L_0$ at a nonzero angle. The nonzero angle requirement is called the *transversality* condition, which effectively dictates that the hypersurface is not parallel to the through-going trajectories, thus the trajectories truly intersect the cross-section $\crossSection$.

Consider now orbits of ([-@eq-poincare-map-system]) near the cycle $L_0$ and recall that the cycle $L_0$ itself is an orbit which starts at point $\vi x_0$ on $\crossSection$ and returns to the same point on $\crossSection$. As the @thm-exists-unique-smooth-ode-solution guarantees the solution of ([-@eq-poincare-map-system]) depend smoothly on its initial condition, an orbit starting at $\vi x \in \crossSection$ sufficiently close to $\vi x_0$ will transversally intersect the hypersurface $\crossSection$ at some other point $\tilde{\vi x}$ near $\vi x_0$. Therefore, this induces a map $\vi P: \crossSection \to \crossSection$,
$$
\vi x \mapsto \tilde{\vi x} = \vi P(\vi x).
$$

:::{#def-poincare-map}
##### Poincaré map

The map $\vi P$ defined above is called a *Poincaré map* associated with the cycle $L_0$.
:::

Similarly, we can characterize the Poincaré map $\vi P$ using a local coordinates $\vi \xi = (\xi_1, \dots, \xi_{n - 1})$ on $\crossSection$, such that the choice $\vi \xi = \vi 0$ corresponds to $\vi x_0$. Then the Poincaré map can be locally defined as a function $\vi P: \R^{n - 1} \to \R^{n - 1}$, which maps $\vi \xi$ corresponding to $\vi x$ to $\tilde{\vi \xi}$ corresponding to $\tilde {\vi x}$, i.e.,
$$
\vi P(\vi \xi) = \tilde{\vi \xi}.
$$

In other words, the Poincaré map $\vi P$ prescribes a *discrete-time dynamical system* on the hypersurface $\crossSection$. Its origin $\vi \xi = \vi 0$ is a fixed point of this mapping. To our advantage, the stability of the underlying cycle $L_0$ is then equivalent to the stability of the fixed point $\vi \xi_0 = \vi 0$. By @thm-lyapunov-differences, we know the cycle is thus stable if all eigenvalues (also called *multipliers*) $\mu_1, \dots, \mu_{n - 1}$ of the $(n - 1) \times (n - 1)$ Jacobian matrix of $\vi P$,
$$
\Jacobi_{\vi P} = \jacobi_{\vi \xi} \vi P(\vi \xi_0),
$$
are located inside the unit circle $\norm{\vi \mu} = 1$. The Poincaré map will throughout this thesis paint itself a powerful tool in the bifurcation analysis of dynamical systems, and the following lemma hints at its usefulness.

:::{#lem-poincaré-map}
The multipliers $\mu_1, \dots, \mu_{n - 1}$ of the Jacobian matrix $\Jacobi_{\vi P}$ of the Poincaré map $\vi P$ associated with a cycle $L_0$ are independent of the point $\vi x_0$ on $L_0$, the cross-section $\crossSection$, and local coordinates on it.
:::

:::{.proof}
See @Kuznetsov2023, page 27.
:::

Consider now the cycle $L_0$ and let $\vi x^0(t)$ denote its corresponding periodic solution of ([-@eq-poincare-map-system]) with the period $T_0$, i.e., $\vi x^0(t + T_0) = \vi x^0(t)$. Then any solution $\vi x(t)$ of ([-@eq-poincare-map-system]) can be written as
$$
\vi x(t) = \vi x^0(t) + \vi u(t),
$$
where $\vi u(t)$ stands for the deviation of the solution from the referential periodic solution. Then,
\begin{align*}
\dvi u(t) &= \dvi x(t) - \dvi x^0(t) \\
	&= \vi f(\vi x^0(t) + \vi u(t))  - \vi f(\vi x^0(t)) \\
	&= \Jacobi(t) \vi u(t) + O(\norm{\vi u(t)}^2).
\end{align*}
Omitting $O(\norm{\vi u(t)}^2)$ terms gives us a linear $T_0$-periodic system
$$
\dvi u = \Jacobi(t) \vi u, \quad \vi u \in \R^n,
$$ {#eq-variational-about-cycle}
where $\Jacobi(t) = \jacobi_{\vi x} \vi f(\vi x^0(t))$, and $\Jacobi(t + T_0) = \Jacobi(t)$.

:::{#def-variational-equation-about-cycle}
System ([-@eq-variational-about-cycle]) is called the *variational equation* about the cycle $L_0$.
:::

As the variational equation describes the evolution of perturbations in the proximity of the cycle $L_0$, naturally its stability depends on the properties of the variational equation.

:::{#def-monodromy-matrix}
The time-dependent matrix $\vi M(t)$ is called the *fundamental matrix solution* of ([-@eq-poincare-map-system]) if it satisfies
$$
\dvi M = \Jacobi(t) \vi M,
$$
with the initial condition $\vi M(0) = \ident_n$. The matrix $\vi M(T_0)$ is called a **monodromy matrix** of the cycle $L_0$.
:::

:::{#thm-floquet-exponents}
##### Floquet exponents

The monodromy matrix $\vi M(T_0)$ has eigenvalues (called *Floquet exponents* or *multipliers*)
$$
1, \mu_1, \dots, \mu_{n - 1},
$$
where $\mu_i$ are the multiplier of the Poincaré map $\vi P$ associated with the cycle $L_0$, see @lem-poincaré-map.
:::

:::{.proof}
See @Kuznetsov2023, page 30, for a sketch of the proof.
:::

### Stochastic Dynamical Systems {#sec-stochastic-dyn-systems}

So far, we have only considered deterministic dynamical systems. Their defining feature was the absence of abrupt changes, i.e., the total lack of randomness. Contrastingly, in practice one has to constantly deal with noise in measurements of the studied system. This effectively results in a stochastic dynamical system induced by the stochastic random process arising from the measurements. Let us note this section is primarily based on @Kloeden1992.

Let us first introduce necessary theory of stochastic analysis.

:::{#def-stochastic-process}
##### Stochastic process

Let $(\eventSet, \sAlgebra, P)$ be a **probability space** and $\timeSet \subseteq \R$ some index set of times. Then **random/stochastic process** $\set{\rX(t, \omega); \; t \in \timeSet}$ is a mapping
$$
\rX : \timeSet \times \eventSet \to \R,
$$
which is $\sAlgebra$-measurable, i.e.,
$$
\forall t \in \timeSet, \; \forall B \in \borelAlgebra: \; \set{\omega \in \eventSet : \; \rX(t, \omega) \in B} \in \sAlgebra.
$$
For a fixed $\omega \in \eventSet$, the mapping $\rX(t) = \rX(t,\omega)$ is called a **trajectory**. Similarly, for a fixed $t\in \timeSet$ the resulting $\rX(\omega) = \rX(t,\omega)$ **is a random variable**.
:::

:::{#def-wiener-process}
##### Wiener process

**Wiener process**, sometimes also called **Brownian motion**, is a random process $\set{\rW(t, \omega); \; t \geq 0}$ satisfying

1. $\rW(0, \omega) = 0$,
2. trajectories are *almost surely* continuous, i.e.,
	$$
	P(\set{\omega \in \eventSet: \; \text{trajectory } t \mapsto \rW(t, \omega) \text{ is discontinuous}}) = 0,
	$$
3. for all $0 \leq s_1 < t_1 \leq s_2 < t_2 \dots \leq s_k < t_k \leq \cdots$, the **increments** of Wiener process
	$$
	\set{\diff \rW_1(\omega), \diff \rW_2(\omega), \dots}
	$$
	are **stochastically independent** random variables with Gaussian probability distribution
	$$
	\diff \rW_k \sim \normalD{0, t_k - s_k},
	$$
	where $\diff \rW_k(\omega) = \rW(t_k, \omega) - \rW(s_k, \omega)$ for $k = 1,2,\cdots$.
:::

:::{#thm-wiener-process-properties}
##### Properties of Wiener process

Let $\set{\rW(t);\; t \geq 0}$ be Wiener process. Then, for all $t,s \geq 0$, it holds^[Let us note $\acov(s,t) = \cov(\rX(s), \rX(t)) = \Expect{(\rX(s) - \expect \rX(s))(\rX(t) - \expect \rX(t))}$ denotes the *autocovariance function* and $\acf(s,t) = \corr(\rX(s), \rX(t)) = \frac {\cov (\rX(s), \rX(t))} {\sqrt{\variance \rX(s) \variance \rX(t)}}$ the *autocorrelation function* of a stochastic process $X(t)$.]

1. $\procMean(t) = 0$,
2. $\acov(t,t) = t$,
3. $\rW(t) \sim \normalD{0,t}$,
4. $\acov(s,t) = \min\set{s,t}$,
5. $\acf(s,t) = \sqrt{\frac {\min\set{s,t}} {\max\set{s,t}}}$.
:::

:::{.proof}
See @Kloeden1992, page 28.
:::

In other words, in @def-stochastic-process we have constructed process which selects a random trajectory with each sample. Moreover, we have defined in @def-wiener-process a special process which is almost always continuous everywhere but differential nowhere (not unlike the Weierstrass function) with **stochastically independent** increments on disjunct intervals!

Our goal in this endeavour is to construct a sensible calculus on stochastic processes, which we could then use to understand deterministic dynamical systems perturbed by (small) stochastic noise. Let us consider a (trivial) differential equation (mainly focus on the differential form)
$$
\deriv {x(t)} t = a x(t) \iff \d x(t) = a x(t) \dd t,
$$
which has the solution $x(t) = e^{at}$, where $x(t)$ often represents size of some population. Taking $a = r + \sigma \rve(t, \omega)$, where $\rve(t, \omega)$ is a random process, the population size now becomes a random variable
$$
\d \rX(t,\omega) = \brackets{r + \sigma \rve(t, \omega)} \rX(t, \omega) \dd t,
$$
which is a **stochastic differential equation** (SDE). For a moment, let us use *differences* instead of *differentials*, i.e.,
\begin{align*}
\diff \rX(t,\omega) &= \brackets{r + \sigma \rve(t, \omega)} \rX(t, \omega) \, \diff t \\
  &= r \rX(t, \omega) \, \diff t + \sigma \rX(t, \omega) \underbrace{\rve(t)  \, \diff t}_{\diff \rZ(t)}.
\end{align*}

What is the form of the random process $\rZ(t)$, such that $\diff \rZ(t) = \rve(t) \, \diff t$, where $\rve(t)$ is a *Gaussian white noise*? To a careful reader, this may seem at least a little reminiscent of a Wiener process. In other words, differences $\diff Z(t)$ are *Gaussian white noise*^[A random variable is called Gaussian white noise if it has normal distribution with zero mean.] and if we require (almost sure) continuity and $\rZ(0) = 0$, we get that $\rZ(t)$ is the Wiener process -- that is $\diff \rW(t)$ have the same properties as $\rve(t) \diff t$. With the limit transition $\lim_{\diff t \to 0}$ in the $\ltwo$ sense we get, arguably after much more mathematics,
$$
\d \rW(t) = \rve(t) \dd t,
$$
which can be understood as *distributional derivative*. Now let us return to the original stochastic differential equation, that now becomes
$$
\dd \rX(t,\omega) = r  \rX(t, \omega) \dd t + \sigma  \rX(t, \omega) \overbrace{\rve(t, \omega) \dd t}^{\d \rW(t)},
$$
which we are tasked with solving for a random process $\rX(t)$, $t \geq 0$, that satisfies this SDE. This rather simple SDE prescribes so called *geometric Brownian motion*. In general, a random process $\rX(t)$ is called **Itô process**, if it is a solution to
$$
\dd \rX(t) = \rnd U(t) \dd t + \rnd V(t) \dd \rW(t), \; \rX(0) = \rX_0,
$$
where $\rnd U(t, \omega), \rnd V(t, \omega)$ are random processes satisfying certain conditions and $\rX_0$ is required to have finite second moment.

## Dynamical Systems with Delays {#sec-dynamical-systems-delays}

To understand how delays influence dynamical systems and define a *semidynamical system*, we have to generalize our notion of a differential equation. This modification will rely on introducing a deviating argument, i.e., some of the derivatives of the differential equation will be evaluated at different argument values. This section will be primarily sourced from @Hale1977, @Hale1993, @Kolmanovskii1992, @Diekmann1995, @Smith2010, and @Guo2013.

### Functional Differential Equations

So far, we have mainly discussed *ordinary differential equations*, which are equations relating the values of an unknown function and some of its derivatives at a single and the same argument value, see ([-@eq-autonomous-ode-system]) and ([-@eq-implicit-ode-system]), e.g. $F(t, x, \dot{x}, \ddot{x}) = 0$.

In contrast, a *functional equation* (FE) is an equation connecting outputs of an unknown function evaluated at different argument values. As an example, $x(-t) + 3x(2t) = 0$, $x(x(t)) = x(t) + 2$, and $x(t) = tx(t+1) - \brackets{x(t-2)}^3$ are all examples of functional equations. The differences between the argument values of an unknown function and $t$ (its "default" argument) in a FE are called *argument deviations*. If all argument deviations are constant (like in the last example shown above), then the FE is called a *difference-functional equation*.

Although, we have so far shown only examples of FEs with *discrete* (or *concentrated*) argument deviations, another possibility are FEs with *continuous* and *mixed* (both continuous and discrete) *argument deviations*. They are called *integral* and *integral-functional* (or *integral-difference*) equations.

We can further combine these notions of ordinary differential equations and functional equations, yielding in the process *functional differential equations* (FDEs). FDEs can also contain discrete, continuous or mixed argument deviations. Thus, one can introduce *differential-difference equations*, and *integro-differential equations* in a similar way as seen above.

The aforementioned generalization in its full form leads to *functional differential equations* -- equations describing the relation between the unknown function and some of its derivatives for, in general, different argument values. Our main subject of study will be a subclass of *differential-difference equations* called the *functional differential equations with aftereffects*, which are of form
$$
\vi x^{(m)}(t) = \vi f\brackets{t, \vi x^{(m_1)}(t - \tau_1(t)), \dots, \vi x^{(m_k)}(t - \tau_k(t))},
$$
where $\vi x(t) \in \R^n$, $m_1, \dots, m_k \geq 0$, and $\tau_1(t), \dots, \tau_k(t) \geq 0$. They can be further classified as:

- *retarded FDEs* (RFDEs) or equivalently *delay differential equations* (DDEs), if $\max \set{m_1, \dots, m_k} < m$;
- *neutral FDEs* (NFDEs), if $\max \set{m_1, \dots, m_k} = m$;
- *advanced FDEs* (AFDEs), if $\max \set{m_1, \dots, m_k} > m$.

Let us also note that the argument deviations can, in theory, be dependent on the state, e.g. $\dot{x}(t) = f(t, x(t), x(t - h(t, x(t))))$, but we shall omit them from our considerations.

<!-- TODO: Check that it can really be like this! -->
::: {.callout-caution #cau-dde-convention}
### Note on naming convention

For clarity and brevity, throughout this thesis *RFDEs with (discrete) constant delays* will be called *delay differential equations* (DDEs), although the term can be more general in other literature.
:::

### Method of Steps {#sec-method-of-steps}

All throughout this work, we shall see many parallels between ODEs and DDEs. While their connection is intricate and would require a more thorough discussion, one way it can be partly understood is via the *method of steps* -- a way of solving delay differential equations. This subsection is mainly based on @Smith2010.

To begin gently, we will start with a simple case of $x \in \R$. Let us thus consider a nonlinear DDE of form
$$
\dot x(t) = f(t, x(t), x(t - r))
$$ {#eq-1d-dde}
with a single delay $r > 0$. Assume that $f(t,x,y)$ and $f_x(t,x,y)$ are continuous on $\R^3$. Let $s \in \R$ and a continuous *history* function $\phi: [s - r, s] \to \R$ be given. We aim to find a solution of ([-@eq-1d-dde]) such that
$$
x(t) = \phi(t), \; s-r \leq t \leq s
$$ {#eq-1d-dde-initial-cond}
and satisfying ([-@eq-1d-dde]) on $s \leq t \leq s + \sigma$ for some $\sigma > 0$. As a careful reader might notice, we must interpret $\dot x(s)$ as a *right-hand* derivative at $s$.

The system of equations ([-@eq-1d-dde]) and ([-@eq-1d-dde-initial-cond]) can now be solved with the so-called *method of steps* as follows. For $s \leq t \leq s + r$, $x(t)$ must satisfy the initial-value problem (IVP) for the following ODE:
$$
\dot y(t) = \underbrace{f(t, y(t), \phi(t - r))}_{g(t,y)}, \; y(s) = \phi(s), \; s \leq t \leq s + r.
$$

From the continuity of $f$ and $f_x$ immediately follows the continuity of $g$ and $g_y$, thus existence of an unique local solution is guaranteed by classic results from the ODE theory, see, for example, @Chicone2006. Moreover, if this local solution $x(t)$ exists on the entire interval $s \leq t \leq s + r$, then, together with the history $\phi$, we know the solution $x(t)$ of ([-@eq-1d-dde])-([-@eq-1d-dde-initial-cond]) on $[s-r, s+r]$ and we may repeat the presented argument to extend our solution to the right. Indeed, considering now the interval $s+r \leq s \leq s + 2r$, a solution of $x(t)$ of ([-@eq-1d-dde])-([-@eq-1d-dde-initial-cond]) must now satisfy the following ODE problem:
$$
\dot y(t) = f(t, y(t), x(t - r)), \; y(s+r) = x(s+r), \; s+r \leq t \leq s+2r.
$$
Just as before, from continuity of $f$ and $f_x$ yields a local unique solution, by abuse of notation called again $x(t)$, defined on some subinterval $[s+r, \sigma) \subset [s+r, s + 2r]$ or, possibly, the entire interval. Naturally, $x(t)$, now existing on $[s-r, \sigma)$ where $\sigma > s + r$, is again a solution of ([-@eq-1d-dde])-([-@eq-1d-dde-initial-cond]). Finally, if the solution exists on the entire interval $[s+r, s+2r]$ we can perform another *step*, i.e., repeat this procedure, to extend $x(t)$ further to the right to $[s+2r, s+3r]$ or some subinterval. 

:::{#thm-1d-single-delay-method-of-steps}
##### Single-delay method of steps on $\R$

Let $f(t,x,y)$ and $f_x(x,y,t)$ be continuous on $\R^3$, $s \in \R$, and let $\phi: [s-r, s] \to \R$ be continuous history function. Then there exists $\sigma > s$ and a unique solution of the initial-value problem ([-@eq-1d-dde])-([-@eq-1d-dde-initial-cond]) on $[s-r, \sigma]$
:::

:::{.proof}
Follows directly from calculations above.
:::

A careful reader might notice that @thm-1d-single-delay-method-of-steps guarantees only a local solution, but we might want a solution for any $t \geq s$. We will use the notation $[s-r, \sigma\rco$ to denote either the open interval $[s-r, \sigma)$ or the closed on $[s-r, \sigma]$.

From the uniqueness follows that for two solutions $x(t)$ on $[s-r, \sigma\rco$ and $\hat x(t)$ on $[s-r, \rho\rco$, the equality $x(t) = \hat x(t)$ must hold for all $t$, such that both sides of the equality are defined. Moreover, if $[s-r, \sigma\rco \subset [s-r, \rho\rco$, then $\hat x$ is called an *extension* of $x$ and we write $x \subset \hat x$.

One can prove there exists a *unique* maximally defined solution, i.e., one for which there are no extensions, $x : [s-r, \sigma) \to \R$, similarly as for ODEs, for $\sigma \in \R \cup \set{\infty}$. Such solution is called *non-extendable* and is necessarily defined on a right-open interval $[s-r, \sigma)$. Indeed, if $\sigma < \infty$ and $x$ were a solution on $[s-r, \sigma]$, then, by @thm-1d-single-delay-method-of-steps, it could be extended to a larger interval, which contradicts non-extendability of $x$.

:::{#thm-dde-finite-time-blow-up}
##### Finite-time blow-up

Let $f$ satisfy the conditions of @thm-1d-single-delay-method-of-steps and let $x: [s-r, \sigma) \to \R$, $\sigma \in \R \cup \set{\infty}$, be the non-extendable solution of the initial value problem ([-@eq-1d-dde])-([-@eq-1d-dde-initial-cond]). If $\sigma < \infty$, then
$$
\lim_{t \to \sigma^-} \absval{x(t)} = \infty.
$$
:::

:::{.proof}
See @Smith2010, page 26.
:::

::: {.callout-note #nte-general-dde}
##### On multiple delays and $\vi x \in \R^n$
One can rather easily show that @thm-1d-single-delay-method-of-steps and @thm-dde-finite-time-blow-up extend to the case of $\vi x \in \R^n$ and $\vi f : \R \times \R^n \times \R^n \to \R^n$. Similarly, it can also be generalized to multiple discrete delays $r_1 < \dots < r_H$ where
$$
\vi f = \vi f(t, \vi y(t), \vi y(t - r_1), \dots, \vi y(t - r_H))
$$
with little to no change.
:::

<!-- TODO: Write about method of steps in Julia -->

### Notes on Delay Differential Equations

Consider a DDE of form
$$
\dvi x(t) = \vi f(t, \vi x(t), \vi x(t - \tau_1), \dots, \vi x(t - \tau_H)),
$$ {#eq-dde-general}
with $0 = \tau_0 < \tau_1 < \dots < \tau_H$. For brevity, we will denote $\tau := \tau_H$ and
$$
\vi x_t(s) := \vi x(t+s), \; -\tau \leq s \leq 0,
$$
which, informally, prescribes the value of solution $\vi x$ up to time $t$ delayed by $s$. In other words, we can view the trajectory of our solution as the curve $t \to \vi x_t$ in the state space $\contStateSpace = \contf{[-\tau, 0], \R^n}{}$ with supremum norm
$$
\norm{\vi \phi} = \sup_{-\tau \leq s \leq 0} \norm{\vi \phi(s)},
$$
a Banach space of continuous functions mapping the interval $[-\tau, 0]$ to $\R^n$ with the topology of uniform convergence, see @Hale1993. Thus, we can reformulate ([-@eq-dde-general]) as
$$
\dvi x(t) = \vi F(t, \vi x_t),
$$ {#eq-rfde}
which can generally represent any RFDE, with $\vi F : \timeSet \times \contStateSpace \to \R^n$ defined as
$$
\vi F(t, \vi \phi) = \vi f(t, \vi \phi(-\tau_0), \vi \phi(-\tau_1), \dots, \vi \phi(-\tau_H)).
$$ {#eq-dde-functional}

Most often, we will encounter the following *autonomous* initial-value problem
$$
\begin{aligned}
	\dvi x(t) &= \vi f(\vi x(t), \vi x(t - \tau_1), \dots, \vi x(t - \tau_H)), \\
	\vi x_{\sigma} &= \vi \phi,
\end{aligned}
$$ {#eq-dde-problem-autonomous}
where $\sigma \in \R$ is the initial time and $\vi \phi \in \contStateSpace$ is the state of system at time $\sigma$, i.e., the $\tau$-long history function corresponding to the interval $[\sigma - \tau, \sigma]$. For completeness sake, we also add that general RFDE initial-value problem reads as follows
$$
\begin{aligned}
	\dvi x(t) &= \vi F(t, \vi x_t), \\
	\vi x_{\sigma} &= \vi \phi.
\end{aligned}
$$ {#eq-rfde-problem}

Last, but not least, we shall denote by
$$
\jacobi_{\vi \tau_i} \vi f = \partialOp{\vi \xi_{i}} \vi f(t, \overbrace{\vi x(t - \tau)}^{\vi \xi_0}, \overbrace{\vi x(t - \tau_1)}^{\vi \xi_1}, \dots, \overbrace{\vi x(t - \tau_H)}^{\vi \xi_H})
$$
the Jacobian matrix of $\vi f$ corresponding to the $i$-th delayed state input. In other words, we may write the linearization of ([-@eq-dde-problem-autonomous]) around equilibrium $\vi x^*$, i.e., $\vi f(\vi x^*, \dots, \vi x^*) = \vi 0$, as
$$
\vi f(\vi x(t)) \approx \vi f(\vi x^*, \dots, \vi x^*) + \sum_{i = 0}^H \jacobi_{\vi \tau_i} \vi f(\vi x^*, \dots, \vi x^*) \vi x(t - \tau_i),
$$ {#eq-dde-linearization}
which follows from the Taylor expansion of $\vi f$.

#### Backward Extension {#sec-backward-extension-dde}

Let us for a moment return to ([-@eq-rfde-problem]). So far, we have discussed its solution for $t > \sigma$, but, sometimes, we may solve it backwards in time for $t < \sigma$, i.e. perform a *backward extension* of the initial history $\phi$. Importantly, it should be evident there is a fundamental asymmetry between the past and the future for DDEs (recall they are only a special case of RFDEs), which is non-existent in the case of ODEs. Indeed, as one can see from, for example, @Chicone2006, there is no fundamental distinction between solving forward or backward in time.

Per @Smith2010 and @Hale1993, we say that $\vi x : [\sigma - \tau - \alpha, \sigma] \to \R^n$ for $\alpha > 0$ is a (backward) solution of the initial-value problem given by ([-@eq-rfde-problem]) if $\vi x$ is continuous, $\vi x$ satisfies the initial condition and
$$
\dvi x(t) = \vi F(t, \vi x_t), \; t \in [\sigma - \alpha, \sigma].
$$
Because $\vi x_{\sigma} = \vi \phi$ must hold as well, due to the initial condition, we get that $\vi x(t) = \vi \phi(t - \sigma)$ must be continuously differentiable for $t \in [\sigma - \alpha, \sigma]$. As $\vi \phi \in \contStateSpace$, we can equivalently say that $\vi \phi$ must be continuously differentiable on $[-\minOf{\alpha, \tau}, 0]$. This significantly constraints the space of all admissible elements in $\contStateSpace$. Furthermore, because the equality must hold at $t = \sigma$, we get
$$
\dvi \phi(0) = \dvi x(\sigma) = \vi f(\sigma, \vi x_{\sigma}) = \vi f(\sigma, \vi \phi),
$$
where $\dvi \phi(0)$ denotes the left-hand derivative at $0$. In total, the history function $\vi \phi$ must thus belong to a very limited submanifold $\obj M$ of $\contStateSpace$ where
$$
\obj M = \set{\vi \psi \in \contStateSpace \cap \contf{[-\minOf{\tau, \alpha}, 0], \R^n}{1} : \dvi \psi(0) = \vi f(\sigma, \vi \psi)}.
$$

It is reasonable to assume that for a typical history function $\vi \phi \in \contStateSpace$, these conditions will not be met and therefore backward extension will not be possible. However, if $\vi x: [\sigma - \tau, \sigma + A)$, $A > 0$ is a (forward) solution of ([-@eq-rfde-problem]) and if $\sigma_1 \in (\sigma, \sigma + A)$, then the initial-value problem corresponding to this intermezzo initial condition $(\sigma_1, \vi \psi)$, where $\vi \psi = \vi x_{\sigma_1}$, has a backward solution $\vi x$. It can be shown that many (but not all) solutions of autonomous systems ([-@eq-dde-problem-autonomous]) extend to all $t \in \R$ -- steady-state and periodic solutions can be given as examples.

#### Stability {#sec-dde-stability}

We have already discussed stability for dynamical systems in @def-invariant-set-stable. Stability for DDEs can be defined analogously, which will be summarized in the following definition (per @Smith2010 and @Hale1993).

:::{#def-dde-stability}
##### Stability in Delay Differential Equations

Consider ([-@eq-rfde-problem]) and suppose that $\vi F(t, \vi 0) = \vi 0$, $t \in \R$, is satisfied so that $\vi x(t) = \vi 0$ is a solution. The solution $\vi x = \vi 0$ is called

- *stable* if for any $\sigma \in \R$ and $\ve > 0$, there exists $\delta = \delta(\sigma, \ve) > 0$ such that $\vi \phi \in \contStateSpace$ and $\norm{\vi \phi} < \delta$ implies that $\norm{\vi x_t(\sigma, \vi \phi)} < \ve$, $t \geq \sigma$;^[For clarity, we use $\vi x(t, \sigma, \vi \phi)$ to denote the solution of ([-@eq-rfde-problem]).]
- *asymptotically stable* if it is stable and if there exists $b(\sigma) > 0$ such that whenever $\vi \phi \in \contStateSpace$ and $\norm{\vi \phi} < b(\sigma)$, then $\vi x(t, \sigma, \vi \phi) \to 0$ as $t \to \infty$;
- *unstable* if it is not stable.
:::

For a non-zero solution $\vi y(t)$ of ([-@eq-rfde-problem]) defined on $t \in \R$, its stability properties mimic those of the zero solution of
$$
\dvi z(t) = \vi f(t, \vi z_t + \vi y_t) - \vi f(t, \vi y_t).
$$ {#eq-non-zero-stability}
Indeed, let $\vi \xi(t)$ be another solution of ([-@eq-rfde-problem]) and put $\vi z(t) = \vi \xi(t) - \vi y(t)$. Then $\vi z_t = \vi \xi_t - \vi y_t$ and thus (by using ([-@eq-rfde-problem]) on $\vi \xi_t$ or $\vi y_t$)
$$
\dvi \xi(t) - \dvi y(t) = \vi f(t, \vi \xi_t - \vi y_t + \vi y_t)  - \vi f (t, \vi y_t),
$$
which yields that $\vi z$ is a solution to ([-@eq-non-zero-stability]), which was to be shown.

Moreover, we shall also define a *solution operator* (or *solution map*) for autonomous RFDEs. This will become useful later when discussing stability of equilibria in the case of DDEs from the perspective of their linearization, see @sec-dde-equilibrium-localization.

:::{#def-dde-solution-oper}
Consider the autonomous DDE problem ([-@eq-dde-problem-autonomous]).The *solution operator* $\solOp(t, \sigma) : \contStateSpace \to \contStateSpace$ from time $\sigma$ to $t$, such that $t \geq \sigma$, is defined as
$$
\solOp(t,\sigma) \vi \phi \letDef \vi x_t(\sigma, \vi \phi).
$$ {#eq-dde-solution-oper}

In the case of $\sigma = 0$, we abuse the notation to write $\solOp(t)$. 
:::

In other words, the solution operator $\solOp(t)$ maps the initial segment $\vi \phi$ onto the solution segment $\vi x_t$ at time $t$. Note that ([-@eq-dde-solution-oper]) is equivalent to (considering $\sigma = 0$)
$$
(\solOp(t) \vi \phi)(\tht) = \vi x(t + \tht), \; - \tau \leq \tht \leq 0, t \geq 0.
$$ {#eq-dde-solution-oper-theta}
It can be shown that, see @Hale1993,
$$
\begin{aligned}
\solOp(0) &= \id, \\
\solOp(t) \solOp(s) &= \solOp(t + s), \; t,s \geq 0, \\
\solOp(t)\vi \phi &\text{ is continuous in } (t, \vi \phi),
\end{aligned}
$$ {#eq-dde-solution-oper-semigroup}
thus $\set{\solOp(t)}$, $t \geq 0$, is a *strongly continuous semigroup of transformations* on a subset of $\contStateSpace$ (see @Hale1993 or @Curtain1995 for more information on the subject). Let us remark we assume $t,s$ are allowed to range over an interval which may be dependent on $\vi \phi \in \contStateSpace$.

### Semidynamical Systems Induced by Delay Differential Equations {#sec-semidyn-sys-induced-by-dde}

So far, we have only seen examples of *continuous-time* dynamical systems, which have inherently been symmetric in time, i.e., *invertible*. In other words, these systems did not distinguish between the future and the past. As an example, consider the following ODE and its induced continuous-time dynamical system,
$$
\dvi x(t) = \vi f(t, \vi x), \; \vi x(s) = \vi x_0.
$$
When solving such ODE, it is only our choice to integrate forward in time, but backward integration is just as possible. On the other hand, as we have seen in @sec-backward-extension-dde, delay differential equations are not always solvable backward in time. 

:::{#def-semidynamical-system}
**Semidynamical system** is a triple^[For semidynamical systems, we will use $\contStateSpace$ instead of $\stateSpace$ to emphasize that $\vi x \in \contStateSpace$ will typically be some (vector-valued) history function.] $(\widetilde{\timeSet}, \contStateSpace, \evolOp)$, where
$$
\widetilde{\timeSet} = \set{(t,s) \in \timeSet \times \timeSet \divider t \geq s},
$$
$\contStateSpace$ is a metric space and $\evolOp : \widetilde{\timeSet} \times \contStateSpace \to \contStateSpace$ is continuous map, which satisfies the *deterministic* and *composition* properties from @def-dynamical-system.
:::

The difference between @def-dynamical-system and @def-semidynamical-system is rather subtle. It lies in the restriction to $\widetilde{\timeSet}$, which permits only projection forward in time. Indeed, by using $\widetilde{\timeSet} = \timeSet \times \timeSet$, we get the usual dynamical system. Note, that autonomous semidynamical system is defined analogously as in @def-autonomous-dynamical-system. Also, basic concepts defined for dynamical systems, see @sec-basic-concepts, mostly extend to semidynamical systems (for example, we only consider $\omega$-limit point and set).

:::{#lem-autonomous-semidynamical-system}
Semidynamical system $(\widetilde{\timeSet}, \contStateSpace, \evolOp)$ is autonomous if and only if whenever $\vi x(t)$ is a solution defined on subset $I \subseteq \timeSet$ and $\tau \in \timeSet_G$, then $\vi x(t + \tau)$ is a solution on $I - \tau$, where $I - \tau = \set{t - \tau \divider t \in I}$.
:::

:::{.proof}
Can be adapted from @Smith2010, page 63.
:::

As an example of an autonomous system, one can consider the delayed logistic equation, see @Hutchinson1948,
$$
\dot{n}(t) = a \cdot \brackets{1 - \frac{n(t - T)} K} n(t),
$$
which assumes, among other facts, a constant growth rate $a$. Should the growth rate $a = a(t)$ be subject to change in time (for example by external influences), yielding
$$
\dot{n}(t) = a(t) \cdot \brackets{1 - \frac{n(t - T)} K} n(t),
$$
then it prescribes a **non**-autonomous semidynamical system. Analogously to the dynamical system case, the evolution operator $\evolOp$ of an autonomous semidynamical system is called a *semiflow*.

For compatibility with the source material, see @Smith2010, we will now consider an initial-value problem ([-@eq-rfde-problem]) for a RFDE, though for our purposes a DDE would suffice,
$$
\dvi x(t) = \vi F(t, \vi x_t), \; \vi x_\sigma = \vi \phi,
$$
where $\sigma \in \R$, $\vi F$ is continuous, and $\vi \phi \in \contStateSpace$. Let us assume there is a unique solution $\vi x(t, \sigma, \vi \phi)$ of ([-@eq-rfde-problem]) defined for $t \geq \sigma$. While this condition is hard to ensure in practice, it is nonetheless necessary for the definition of the induced semidynamical system. Denote by $\vi x_t(\sigma, \vi \phi) \in \contStateSpace$ the state of the system at time $t$, defined, as usual, by
$$
\vi x_t(\sigma, \vi \phi)(\tht) = \vi x(t + \theta, \sigma, \vi \phi), \; -\tau \leq \tht \leq 0.
$$

:::{#prp-dde-induced-semidynamical-system}
The map $\evolOp(t,\sigma,\vi \phi) = \vi x_t(\sigma, \vi \phi)$ defines a semidynamical system on $\contStateSpace$ with $\timeSet = [\sigma - \tau, \infty)$ and its corresponding $\widetilde{\timeSet}$.
:::

:::{.proof}
See @Smith2010, page 65.
:::

## Numerical Methods

As the title may suggest, computational aspects of ODEs, DDEs and other mathematical problems will play a key role in this thesis. For completeness' sake, a brief overview of numerical integrators (also called *solvers*) for ODEs, DDEs and stochastic differential equations (SDEs) will be given, as well as basic methods of one-dimensional optimization. Lastly, Newton-Raphson method will be discussed.

### Numerical integration of ODEs {#sec-integrating-odes}

Solving, or numerically integrating, ordinary differential equations can be seen as a backbone of this thesis. As such, we will introduce two approaches, Euler method and Runge-Kutta method. This subsection is mostly based on @Butcher2016, @Hairer2008 and @Trefethen1994.

Consider an ODE of form
$$
\dvi x(t) = \vi F(t, \vi x(t)), \; \vi x(t_0) = \vi x_0,
$$ {#eq-ode-problem-to-solve}
which we want to integrate on the interval $[t_0, t_N]$. By Taylor expansion at $t_0$, we can write
$$
\vi x(t) = \vi x(t_0) + \dvi x(t_0) (t - t_0) + O(t^2).
$$ {#eq-euler-method-taylor}
Setting $t = t_0 + \diff t_1$ yields 
$$
\vi x(t_0 + \diff t_1) \approx \vi x(t_0) + \dvi x(t_0) (t_0 + \diff t_1  - t_0) = \vi x(t_0) + \vi F(t_0, \vi x(t_0)) \diff t_1.
$$

Repeating this process on the entire interval $[t_0, t_N]$ gives us @alg-euler-method. Let us note that often an equidistant stepsize is used, e.g. $\diff t_k = \diff t = \frac {t_N - t_0} N$.

::: {.callout appearance="simple" #alg-euler-method}
##### Euler method (explicit)
**Input:** ODE in form ([-@eq-ode-problem-to-solve]), stepsizes $\seqnc{\diff t}{i}{1}{N}$ \
**Output:** Sequence of $N$ points $\seqnc{\vi x}{i}{1}{N}$ \
**begin** \
&emsp;&emsp;**for** $i = 1$ **to** $N$ **do** \
&emsp;&emsp;&emsp;&emsp;$\vi x_i \gets \vi x_{i - 1} + \vi F(t_{i - 1}, \vi x_{i - 1}) \diff t_i$ \
&emsp;&emsp;**end** \
**end**
:::

Whilst the Euler method is simple, it does have its drawbacks mainly in the accuracy. For quantification of this issue, we shall define several notions of errors of a numerical integration method.

:::{#def-ode-solver-error}
Let us consider an ODE problem of form ([-@eq-ode-problem-to-solve]) and the solution $\vi x(t)$ to the initial-value problem. Assume $\vi x_k$ is an approximate solution at time $t_k$ and that $\vi x_{k+1}$ is given by $\vi x_{k+1} = \vi x_k + \diff t_{k+1} \cdot \incrementF{t_k, \vi x (t_k), \diff t_{k+1}, \vi F}$, where $\incrementFunc$ is the *increment* function^[In general, the increment function $\incrementFunc$ at the $k+1$-st step may depend on $t_0, \dots, t_k$, $\vi x_0, \dots, \vi x_k$, and $\diff t_1, \dots, \diff t_{k + 1}$.], which propagates the solution from $t_k$ to $t_{k+1}$ and represents the chosen method. 

*Local truncation error* (LTE) is defined as
$$
\locTrErr_{k} = \vi x(t_{k+1}) - \vi x(t_k) - \diff t_{k+1} \cdot \incrementF{t_k, \vi x (t_k), \diff t_{k+1}, \vi F}
$$ {#eq-loc-tr-err}
and represents the error the increment function causes when performing a single step. Similarly, *global error* is defined as the cumulative LTE from the initial condition,
$$
\globErr_k = \vi x(t_k) - \vi x_k.	
$$ {#eq-glob-err}
:::

> In general, we seek such method, which fulfills given accuracy while using as few evaluations of $\vi F$ as possible -- the assumption is that the evaluation of $\vi F$ is so costly the remaining operations are almost negligible.

By using ([-@eq-loc-tr-err]) on @alg-euler-method to obtain LTE for Euler method, we get (recalling the Taylor expansion ([-@eq-euler-method-taylor]))
$$
\locTrErr_k = \vi x(t_{k+1}) - \vi x(t_k) - \diff t_{k+1} \cdot \vi F(t_k, \vi x(t_k)) \implies \locTrErr_k = O(\diff t_{k+1}^2).
$$
We say that a method is of order $p$ if $\locTrErr_k = O(\diff t^{p+1})$, i.e., Euler method is first order.

This can surely be improved by using more terms from the Taylor series expansions, see ([-@eq-euler-method-taylor]), but the necessity of computing the derivatives of $\vi F$ is a major drawback, often outweighing any potential benefits. Another possibility would be to allow to computation of next value to be dependent on multiple previous values, leading to multistep methods. Last option --- and the one we shall use --- is to modify a one-step method to produce a intermediate estimates of the solution at multiple different points (called *stages*), which are then combined into the final approximation of the solution at the next step -- this way, we obtain so called **Runge-Kutta** methods.

::: {.callout appearance="simple" #alg-runge-kutta-explicit}
##### $s$-stage explicit Runge-Kutta (ERK) method
**Input:** ODE in form ([-@eq-ode-problem-to-solve]), stepsizes $\seqnc{\diff t}{i}{1}{N}$, $s \in \N$ (the "number of stages"), real coefficients $a_{21}, a_{31}, a_{32},\dots, a_{s1}, a_{s2}, \dots, a_{s,s-1}$, $b_1, \dots, b_s$, and $c_2, \dots, c_s$\
**Output:** Sequence of $N$ points $\seqnc{\vi x}{i}{1}{N}$ \
**begin** \
&emsp;&emsp;**for** $i = 1$ **to** $N$ **do** \
&emsp;&emsp;&emsp;&emsp;calculate
\begin{align*}
	\vi k_1 &\gets \vi F (t_0, \vi x_{i-1}), \\
	\vi k_2 &\gets \vi F (t_0 + c_2 \diff t_i, \vi x_{i-1} + \diff t_i a_{21} \vi k_1), \\
	\vi k_3 &\gets \vi F (t_0 + c_3 \diff t_i, \vi x_{i-1} + \diff t_i (a_{31} \vi k_1 + a_{32} \vi k_2)), \\
	&\;\vdots \\
	\vi k_s &\gets \vi F (t_0 + c_s \diff t_i, \vi x_{i-1} + \diff t_i (a_{s1} \vi k_1 + \dots + a_{s, s-1} \vi k_{s-1}));
\end{align*}
&emsp;&emsp;&emsp;&emsp;set $\vi x_i \gets \vi x_{i-1} + \diff t_i (b_1 \vi k_1 + \dots + b_s \vi k_s)$ \
&emsp;&emsp;**end** \
**end**
:::

Usually, we constrain the coefficients to fulfill
$$
c_m = \sum_{n = 1}^{m - 1} a_{mn},
$$ {#eq-runge-kutta-eval-cond}
which represents the assumption that all points, where $\vi F$ is evaluated, are first order approximations to the solution. It can be shown that ([-@eq-runge-kutta-eval-cond]) significantly simplifies the derivation of order conditions ([-@eq-runge-kutta-order-condition-4-stage]), but for low order, it is not necessary.

Our task is now to choose the coefficients in @alg-runge-kutta-explicit so that the order of the method is maximized. This corresponds to computing the Taylor series expansion for each $\vi k_j$ in the state variable of $\vi F$. By combining these results, we can compare them with the Taylor expansion of $\vi x_i$. Hence, we obtain the following conditions (given for a 4-stage method), using $c_1 = 0$:
$$
\begin{aligned}
\sum_{j} b_j &= 1, &
\sum_{j} b_j c_j &= \frac 1 2, \\
\sum_{j} b_j c_j^2 &= \frac 1 3, &
\sum_{j,m} b_j a_{jm} c_m &= \frac 1 6, \\
\sum_{j} b_j c_j^3 &= \frac 1 4, &
\sum_{j,m} b_j c_j a_{jm} c_m &= \frac 1 8, \\
\sum_{j,m} b_j a_{jm} c_m^2 &= \frac 1 {12}, &
\sum_{j,m,n} b_j a_{jm} a_{mn} c_n &= \frac 1 {24}.
\end{aligned}
$$ {#eq-runge-kutta-order-condition-4-stage}

In other words, if the coefficients of the 4-stage ERK method comply with conditions ([-@eq-runge-kutta-order-condition-4-stage]), the method is of fourth order, i.e., $\locTrErr_i = O(\diff_i t^5)$. Typically, *"the Runge-Kutta"* method is used:
$$
\rcases{
	\vi k_1 &= \vi F\brackets{t_0, \vi x_0} \\
	\vi k_2 &= \vi F\brackets{t_0 + \frac 1 2 \diff t, \vi x_0 + \frac 1 2 \vi k_1 \diff t} \\
	\vi k_3 &= \vi F\brackets{t_0 + \frac 1 2 \diff t, \vi x_0 + \frac 1 2 \vi k_2 \diff t} \\
	\vi k_4 &= \vi F\brackets{t_0 + \diff t, \vi x_0 + \vi k_3 \diff t}
} \; \vi x_1 = \vi x_0 + \diff t \brackets{\frac 1 6 \vi k_1 + \frac 2 6 \vi k_2 + \frac 2 6 \vi k_3 + \frac 1 6 \vi k_4}.
$$ {#eq-runge-kutta-classical}

Throughout this thesis, we will use solvers available in DifferentiaEquations.jl, see @Rackauckas2017, for Julia programming language, see @Bezanson2017, and `ode45` (or `ode23` for stiff ODEs) for MATLAB, see @MATLAB.

### Solving DDEs with Method of Steps {#sec-integrating-ddes}

As invested reader can surely recall, we have already discussed method of steps in @sec-method-of-steps. There, we reformulated the problem of integrating a DDE forward in time as a sequence of ODE initial-value problems, which needed to be integrated on smaller intervals. A detailed treatment of the numerical integration of DDEs can be found in @Bellen2003.

::: {.callout appearance="simple" #alg-method-of-steps}
##### Method of steps
**Input:** DDE in form ([-@eq-dde-problem-autonomous]), ODE numerical integration method $\mathrm{odeSolver}$, number of extensions $k \in \N$ of interval $[-\tau, 0]$ by $\tau$\
**Output:** Sequence of $N \letDef k \sum_{i = 1}^H N_i = k \cdot N_{\tau}$ points $\seqnc{\vi x}{i}{1}{N}$ \
**begin** \
&emsp;&emsp;set $\vi \xi \gets \vi \phi$ and $s \gets \sigma$; \
&emsp;&emsp;define $A(u,v) = (u - 1) N_{\tau} + \sum_{b = 1}^{v} N_b$ \
&emsp;&emsp;**for** $i = 1$ **to** $k$ **do** \
&emsp;&emsp;&emsp;&emsp;**for** $j = 1$ **to** $H$ **do** \
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; define ODE IVP by $\vi y(s) = \vi \xi(s)$ and
$$
\dvi y(t) = \vi f(\vi y(t), \vi \xi(t - \tau_1), \dots, \vi \xi(t - \tau_H));
$$ {#eq-method-of-steps-intermediate}
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; apply $\mathrm{odeSolver}$ to ([-@eq-method-of-steps-intermediate]) yielding $N_j$ points $\seqnc {\vi x} a {A(i, j - 1)} {A(i,j)}$; \
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; set $s \gets s + \tau_j$ and $\vi \xi(\theta) \gets \lcases{
	\vi \xi(\tau_j + \theta), & -\tau_j \geq \theta , \\
	\vi y(s + \theta), & 0 \geq \theta \geq -\tau_j}$ \
&emsp;&emsp;&emsp;&emsp;**end** \
&emsp;&emsp;**end** \
**end**
:::

For brevity, discussion on convergence and other numerical properties is omitted. In implementations, we will predominantly use DelayDiffEq.jl package by @Widmann2022 in Julia or `dde23` in MATLAB.

### Solving SDEs

In @sec-stochastic-dyn-systems, we have presented a framework for dealing with stochastic dynamical systems. These very often arise from noisy measurements of the underlying system. Using discussed concepts, we can represent this as a discrete-time approximation of an Itô process. In particular, we will use the **Euler-Maruyama** approximation. Consider an Itô process $\rX = \set{\rX(t) \divider t_0 \leq t \leq T}$ satisfying the scalar SDE
$$
\dd \rX(t) = a(t, \rX(t)) \dd t + b(t, \rX(t)) \dd \rW(t), \; \rX(t_0) = \rX_0
$$ {#eq-euler-maruyama-sde}
on $t_0 \leq t \leq T$.

For a given discretization $t_0 < t_1 < \dots < t_n = T$ of the time interval $[t_0, T]$, an Euler-Maruyama approximation is a continuous-time stochastic process $\rY = \set{\rY(t) \divider t_0 \leq t \leq T}$ satisfying the following iterative scheme (using $\rY(t_n) = \rY_n$)
$$
\rY_{n+1} = \rY_n + a(t_n, \rY_n) (t_{n+1} - t_n) + b(t_n, \rY_n)(\rW(t_{n+1}) - \rW(t_n))
$$ {#eq-em-iteration-long}
for $n = 0, 1, \dots, N-1$ with initial value $\rY_0 = \rX_0$. For conciseness, we shall denote $\diff t_n = t_{n+1} - t_n$ and call $\delta = \max_n \diff t_n$ the *maximum time step*. Most often, we shall using equidistant discretization, i.e., $t_n = t_0 + n \delta$, and in such case we will use $\diff t = \delta \equiv \diff t_n = (T - t_0) / N$. Similarly, let $\diff \rW_n \letDef \rW(t_{n+1}) - \rW(t_n)$ be the random independent increments of the Wiener process, see @def-wiener-process, corresponding to the discretization. From the definition immediately follows that
$$
\diff \rW_n \sim \normalD{0, \diff t_n} \quad \& \quad \diff \rW \sim \normalD{0, \diff t}.
$$
Thus for equidistant discretization ([-@eq-em-iteration-long]) becomes
$$
\rY_{n+1} = \rY_n + a(t_n, \rY_n) \diff t + b(t_n, \rY_n) \diff \rW,
$$ {#eq-em-iteration}
and as such $\rY$ can be interpreted as a Markov chain. This can be easily extended to a vector-valued SDE,
$$
\dd \vr X(t) = \vi a(t, \vr X(t)) \dd t + \vi B(t, \vr X(t)) \dd \vr W(t), \; \vr X(t_0) = \vr X_0,
$$ {#eq-euler-maruyama-vec-problem}
where, assuming $\vr X(t, \omega) \in \R^n$, we have $\vi a(t, \vr X(t, \omega)) \in \R^n$, $\vi B(t, \vr X(t, \omega)) \in \R^{n \times n}$, and $\dd \vr W(t)$ is a differential corresponding to a vector of Wiener processes with prescribed correlation (and hence $\diff \vr W_n \in \R^{n \times n}$ has a matrix structure relating to the underlying correlation). Finally, this is captured in @alg-euler-maruyama-method.

::: {.callout appearance="simple" #alg-euler-maruyama-method}
##### Euler-Maruyama method
**Input:** SDE in form ([-@eq-euler-maruyama-vec-problem]), time discretization $\seqnc{\diff t}{i}{1}{N}$ \
**Output:** Discretized random process $\vr Y$ to $\seqnc t i 0 N$ \
**begin** \
&emsp;&emsp;set $\vr Y_0 \gets \vr X_0$ by ([-@eq-euler-maruyama-vec-problem]) \
&emsp;&emsp;**for** $i = 0$ **to** $N - 1$ **do** \
&emsp;&emsp;&emsp;&emsp;$\vr Y_{n+1} \gets \vr Y_n + \vi a(t_n, \vr Y_n) \diff t_n + \vi B(t_n, \vr Y_n) \diff \vr W_n$ \
&emsp;&emsp;**end** \
**end**
:::

Let us note that for implementation, we will predominantly use the `EM` method, from @Rackauckas2017, for Julia and a custom implementation for MATLAB. Furthermore, the relevant theory of stochastic functional differential equations (SFDEs) will not be covered in this document to ensure a focused and concise scope. To interested reader, we recommend @Scheutzow2018 for general overview and @Mohammed1986 for more details on linear and affine SFDEs.

### Optimization in $\mathbb{R}$

Optimization is almost ubiquitous in both nature and mathematics. For us, it will prove most fruitful to study optimization in one dimension, where the situation is fortunately the easiest. Most of the material is taken from @Kochenderfer2019 and @Zemanek2021.

The methods we will present can be collectively called *bracketing*, as they rely on iteratively shrinking an interval inside which a local minimum lies. Furthermore, a single-minimum requirement shall be placed on functions to be optimized. For functions on $\R$, this translates to so called *unimodality*.

:::{#def-unimodal-function}
##### Unimodal function

Let $I \subset \R$ be a interval and $f: I \to \R$ a function. We say $f$ is **unimodal** if there exists $x^* \in I$ such that

- $f(x_1) > f(x_2)$ for arbitrary $x_1, x_2 \in I$ satisfying $x_1 < x_2 < x^*$;
- $f(x_1) < f(x_2)$ for arbitrary $x_1, x_2 \in I$ satisfying $x^* < x_1 < x_2$.
:::

::: {.callout-note #nte-unimodality}
##### Unimodality

As a careful reader might notice, unimodal function is necessarily *monotone decreasing* on $(-\infty, x^*) \cap I$ and *monotone increasing* on $I \cap (x^*, \infty)$. Moreover, unimodality implies only *quasi-convexity*^[A function $f: S \to \R$, where $S$ is a real vector space, is *convex* on $S$ if for all $\vi x, \vi y \in S$ and $\lmbd \in [0,1]$ holds $f(\lmbd \vi x + (1 - \lmbd) \vi) \leq \lmbd f(\vi x) + (1 - \lmbd) f(\vi y)$ and *strictly convex* if the inequality is strict. Furthermore, we call it *quasi-convex* on $S$ if for any $\vi x, \vi y \in S$ and $\lmbd \in [0,1]$ we have $f(\lmbd \vi x + (1 - \lmbd) \vi y) \leq \minOf{f(\vi x), f(\vi y)}$.] and, on the other hand, only *strict convexity* implies unimodality of a function on $f: I \to \R$.
:::

:::{#lem-unimodality}
Let $f: I \to \R$ be unimodal on $I$ and consider $x_1, x_2 \in I$ such that $x_1 < x_2$, then

- $f(x_1) \leq f(x_2) \implies x^* \leq x_2$;
- $f(x_1) \geq f(x_2) \implies x_1 \leq x^*$.
:::

:::{.proof}
Follows directly from @def-unimodal-function.
:::

Consider now the following optimization problem
$$
\min_{x \in I} f(x), \quad \text{resp.} \quad \argmin_{x \in I} f(x),
$$ {#eq-unimodal-optim-problem}
for an **unimodal** function $f: I \to \R$, $I = [a,b]$. Furthermore, let $N$ denote the *allowed number of evaluations* of $f$ and assume the accuracy of presented methods is $\absval{\bar x  - x^*}$, where $x^*$ is the exact solution of ([-@eq-unimodal-optim-problem]) and $\bar x$ its approximation found by used method. Using @lem-unimodality, one can easily find the initial bracket to be successively shrunk if it is not provided in the definition of the optimization problem ([-@eq-unimodal-optim-problem]).

#### Bisection Method

Consider now $N = 2k$, $k \in \N$, choose $\delta \in (0, \frac{b - a} 2]$ sufficiently small and let $a_0 \letDef a, b_0 \letDef b$ set the initial bracket $[a_0, b_0]$. We then define
$$
x_i^- \letDef \frac {a_{i - 1} + b_{i - 1}} 2 - \delta \; \& \; x_i^+ \letDef \frac {a_{i - 1} + b_{i - 1}} 2 + \delta
$$ {#eq-bisection-points}
for $i = 1, \dots, k$. Now we can examine in which "half" of interval (including the offset $\delta$) the minimum lies, i.e., we evaluate $f(x_i^-), f(x_i^+)$ and adjust the bracket accordingly (by @lem-unimodality)

- $f(x_i^-) < f(x_i^+) \implies [a_i, b_i] = [a_{i - 1}, x_i^+]$;
- $f(x_i^-) > f(x_i^+) \implies [a_i, b_i] = [x_i^-, b_{i - 1}]$.

The center $\bar x_k$ of the $k$-th bracket is assumed to approximate the exact solution $x^*$ with accuracy $l_k/2$, where 
$$
l_k = \frac {b - a} {2^k} + \frac {(2^k - 1)\delta} {2^{k - 1}}
$$
denotes the length of the $k$-th bracket. It can be seen that $l_k \to 2 \delta$ for $k \to \infty$.

::: {.callout appearance="simple" #alg-bisection-method}
##### Bisection method
**Input:** Optimization problem ([-@eq-unimodal-optim-problem]), initial interval $I = [a,b]$, $\delta \in (0, \frac {b - a} 2]$, number of steps $k \in \N$ \
**Output:** Approximation of minimum $\bar{x}_k$ \
**begin** \
&emsp;&emsp;set $a_0 \gets a, b_0 \gets b$ \
&emsp;&emsp;**for** $i = 1$ **to** $k$ **do** \
&emsp;&emsp;&emsp;&emsp;calculate $x_i^- \gets \frac {a_{i - 1} + b_{i - 1}} 2 - \delta$ & $x_i^+ \gets \frac {a_{i - 1} + b_{i - 1}} 2 + \delta$ \
&emsp;&emsp;&emsp;&emsp;**if** $f(x_i^-) < f(x_i^+)$ **do** \
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;set $[a_i, b_i] \gets [a_{i - 1}, x_i^+]$ \
&emsp;&emsp;&emsp;&emsp;**else if** $f(x_i^-) > f(x_i^+)$ **do** \
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;set $[a_i, b_i] \gets [x_i^-, b_{i - 1}]$ \
&emsp;&emsp;&emsp;&emsp;**else do** \
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;set^[In the case of equality, both options for a new bracket are equally valid.] $[a_i, b_i] \gets [x_i^-, b_{i - 1}]$ \
&emsp;&emsp;&emsp;&emsp;**end** \
&emsp;&emsp;&emsp;&emsp;set $\bar{x}_i \gets \frac {a_i + b_i} 2$ \
&emsp;&emsp;**end** \
**end**
:::

#### Golden Section Method

The bisection method we have presented above has one significant flaw. Every iteration, i.e., every bracket improvement, requires two separate evaluations which are, in general, never used again. Thus, the Golden section method was constructed, requiring only a single evaluation.

::: {.callout-tip #tip-golden-ratio}
##### Golden ratio

Before delving into the technical details, let us note in this subsection $\goldRatio \approx 1.618$ denotes the positive solution of
$$
\goldRatio^2 - \goldRatio - 1 = 0,
$$ {#eq-golden-ratio-quad}
i.e. $\frac 1 \goldRatio \approx 0.618$, and is generally referred to as the *golden ratio*. Equivalently, it is also given as
$$
\frac {a + b} a  = \frac a b = \goldRatio
$$ {#eq-golden-ratio-frac}
for $a > b > 0$ which satisfy the above equality.
:::

Consider an unimodal function $f: I \to \R$ on the interval $I = [a,b]$ subject to optimization problem ([-@eq-unimodal-optim-problem]) and evaluation-count restriction $N \geq 2$ (or desired accuracy $\ve$). Let us relax the bisection method such that
$$
x_i^- = a_{i-1} + \delta_- (b_{i-1} - a_{i-1}), \; x_i^+ = a_{i-1} + \delta_+ (b_{i-1} - a_{i-1})
$$ {#eq-relaxed-bisection}
and we shall attempt to find a values of $\delta_-, \delta_+ \in (0,1)$ such that only 1 iteration is needed. Assume $f(x_i^-) < f(x_i^+)$, then (by @lem-unimodality as in @alg-bisection-method)
$$
[a_i, b_i] = [a_{i-1}, x_i^+] = \parentheses{a_{i-1}, a_{i-1} + \delta_+ (b_{i-1} - a_{i-1})}
$$
and
$$
x_{i+1}^- = a_i + \delta_- (b_i - a_i) \; x_{i+1}^+ = a_i + \delta_+ (b_i - a_i).
$$
If we want to reuse the $f(x_i^-)$ evaluation, then necessarily
$$
\begin{aligned}
	x_{i+1}^+ &= x_i^- \\
	a_i + \delta_+ (b_i - a_i) &= a_{i-1} + \delta_- (b_{i-1} - a_{i-1}) \\
	a_{i-1} + \delta_+ (a_{i-1} + \delta_+ (b_{i-1} - a_{i-1}) - a_{i-1}) &= a_{i-1} + \delta_- (b_{i-1} - a_{i-1}) \\
	\delta_+^2 (b_{i-1} - a_{i-1}) &= \delta_- (b_{i-1} - a_{i-1}) \\
	&\implies \delta_+^2 = \delta_-.
\end{aligned}
$$ 
Now we shall focus on $f(x_i^-) \geq f(x_i^+)$, denoting $\delta = \delta_+$, which by the same argument leads to
$$
[a_i, b_i] = [x_i^-, b_{i-1}] = \parentheses{a_{i-1} + \delta^2 (b_{i-1} - a_{i-1}), b_{i-1}},
$$
which together with the analogous condition $x_{i+1}^- = x_i^+$ yields (using $l_i = b_i - a_i$)
$$
\begin{aligned}
	x_{i+1}^- &= x_i^+ \\
	a_i + \delta^2 (b_i - a_i) &= a_{i-1} + \delta (b_{i - 1} - a_{i - 1}) \\
	a_{i-1} + \delta^2 (b_{i - 1} - a_{i - 1}) + \delta^2 \brackets{b_{i - 1} - a_{i-1} - \delta^2 (b_{i - 1} - a_{i - 1})} &= a_{i - 1} + \delta(b_{i - 1} - a_{i - 1}) \\
	\delta^2 l_{i - 1} + \delta^2 l_{i - 1} - \delta^4 l_{i-1} &= \delta l_{i - 1} \\
	\delta (\delta^3 - 2 \delta + 1) &= 0 \\
	\delta (\delta - 1) (\delta^2 + \delta - 1) &= 0.
\end{aligned}
$$ 
Recall we defined $\delta_-, \delta_+ \in (0,1)$, thus $\delta \in (0,1)$ ruling out $\delta = 0$ and $\delta = 1$ roots. What remains is $\delta^2 + \delta - 1 = 0$, which has the solution $\delta = \frac {\sqrt{5} - 1} 2$. 

Moreover, notice that
$$
\frac{x_{i+1}^- - a_i} {x_{i+1}^+ - a_i} = \frac {a_i + \delta^2 l_i - a_i} {a_i + \delta l_i - a_i} = \delta = \frac {a_i + \delta l_i - a_i} {l_i} = \frac {x_{i+1}^+ - a_i} {l_i},
$$
i.e., we split the interval $[a_i, b_i]$ such that the ratio between the whole $[a_i, b_i]$ and the bigger part $[a_i, x_{i+1}^+]$ is the same as between the smaller part $[a_i, x_{i+1}^-]$ and the bigger part. Rephrasing this ratio equality as (using $\delta^2 = 1 - \delta$)
$$
\begin{aligned}
\frac 1 {\delta} = \frac{x_{i+1}^+ - a_i} {x_{i+1}^- - a_i} &= \frac {l_i} {x_{i+1}^+ - a_i} \\
	&= \frac {x_{i-1}^+ - a_i + b_i - x_{i-1}^+} {x_{i+1}^+ - a_i} \\
	&= \frac {x_{i-1}^+ - a_i + b_i - a_i - \delta l_i} {x_{i+1}^+ - a_i} \\
	&= \frac {x_{i-1}^+ - a_i + l_i - \delta l_i} {x_{i+1}^+ - a_i} \\
	&= \frac {x_{i-1}^+ - a_i + (1 - \delta) l_i} {x_{i+1}^+ - a_i} \\
	&= \frac {x_{i-1}^+ - a_i + \delta^2 l_i} {x_{i+1}^+ - a_i} \\
	&= \frac {x_{i-1}^+ - a_i + a_i + \delta^2 l_i - a_i} {x_{i+1}^+ - a_i} \\
	&= \frac {x_{i-1}^+ - a_i + x_{i-1}^- - a_i} {x_{i+1}^+ - a_i}
\end{aligned}
$$ 
gives us the relation ([-@eq-golden-ratio-frac]) defining the golden ratio, i.e., $\goldRatio = \frac 1 \delta$. In fact, the method bears its name due to this fact. Lastly, see @alg-golden-section-method for implementation.

#### Fibonacci method

Let us now approach the problem from a different direction. Given the minimization problem ([-@eq-unimodal-optim-problem]) and maximum evaluations $N$, we want to shrink the initial bracket as much as possible.

Suppose only 2 evaluations are allowed. Then one possibility is to query $f$ at thirds of the initial interval. The final bracket will have two-thirds length of the initial interval, but it can be improved. Consider the distance between the evaluations $\ve$, then the final bracket is guaranteed to shrink to a half of the original interval (i.e., shrinkage by a factor of 2) as $\ve \to 0$ in the limit sense, see @fig-2-eval-fibonacci.

![Shrinkage by $\ve$-distance between the only two allowed evaluations.](diagrams/2-eval_fibonacci_method.drawio.svg){#fig-2-eval-fibonacci .final}

Suppose $N = 3$ evaluations are now permitted. Then the best course of action is to divide the initial into thirds, which results in the next bracket having $\frac 2 3$-length. If we perform the last $f$-query in the $\ve$-distance from the interior evaluation of the previous round (one is guaranteed to lie inside the next-iteration bracket), then by $\ve \to 0$, in the limit sense, we get a shrinkage by a factor of 3, see @fig-3-eval-fibonacci.

![Sketch of the Fibonacci method bracket shrinkage when $N = 3$.](diagrams/3-eval_fibonacci_method.drawio.svg){#fig-3-eval-fibonacci .final}

In general, this leads to evaluation given by the Fibonacci numbers
$$
F_n = \lcases{
	1, & n \leq 2, \\
	F_{n-1} + F_{n_2}, & n > 2,
}
$$
which prescribe the queries at
$$
x_i^- = a_{i-1} + \frac {F_{N - i - 1}} {F_{N - i + 1}} l_{i - 1}, \quad x_i^+ = a_{i - 1} + \frac {F_{N - i}} {F_{N - i + 1}} l_{i-1}.
$$ {#eq-fibonacci-method-queries}

For more details on the derivation, see @Zemanek2021. Moreover, the Fibonacci series can be written explicitly using *Binet's formula*:
$$
F_n = \frac {\goldRatio^n - (1 - \goldRatio)^n} {\sqrt{5}},
$$ {#eq-binets-formula}
where $\goldRatio$ is the *golden ratio*, see @tip-golden-ratio, from which can be shown
$$
\frac 1 {\rho(i)} = \frac {F_i} {F_{i - 1}} = \goldRatio \frac {1 - s^i} {1 - s^{i - 1}},
$$ {#eq-fibonacci-successive}
where $s = \frac {1 - \sqrt{5}} {1 + \sqrt{5}}$. The algorithm of the Fibonacci method, heavily based on implementation from @Kochenderfer2019, is provided in @alg-fibonacci-method.

### Newton's Method {#sec-newton-method}

Last, but not least, we shall discuss the Newton's, or Newton-Raphson, method for finding roots of a given equation (or a system thereof). The treatment provided here follows @Lacerda2010. Suppose we are given a system of equations
$$
\begin{aligned}
f_1(x_1, \dots, x_n) &= 0 \\
f_2(x_1, \dots, x_n) &= 0 \\
&\vdots \\
f_n(x_1, \dots, x_n) &= 0
\end{aligned} \iff \vi F(\vi x) = \vi 0.
$$ {#eq-newton-method-system}

Let $\vi x^i \in \R^n$ be known and fixed, for example a previous iteration, then ([-@eq-newton-method-system]) can be approximated using Taylor's series in the neighborhood of $\vi x^i$. Corresponding first-order Taylor expansion is
$$
f_k(\vi x) \approx f_k(\vi x^i) + \sum_{j = 1}^n \pDeriv {f_k(\vi x^i)}{x_j} (x_j - x^i_j).
$$

Using vector notation, we can collectively approximate ([-@eq-newton-method-system]) as
$$
\vi F(\vi x^i) + \Jacobi_i (\vi x - \vi x^i) = \vi 0,
$$ {#eq-newton-method-approx}
where $\Jacobi_i = \jacobi_{\vi x} \vi F(\vi x^i)$, i.e., $(\Jacobi_i)_{k,j} = \pDeriv {f_k(\vi x^i)}{x_j}$. Certainly a solution to ([-@eq-newton-method-approx]) approximates the true solution to ([-@eq-newton-method-system]). Then, by sequentially approximating the true solution from points getting closer, the approximations also get more accurate. In other words, we can write the following iterative process to finding the true solution (to an arbitrary accuracy)
$$
\vi x^{i+1} = \vi x^i - \Jacobi_i\Inv \vi F(\vi x^i).
$$ {#eq-newton-iter}

While this formula for Newton's method is very common, we shall also present the *residual* form
$$
\Jacobi_i \cdot \diff \vi x^{i+1} = \vi R(\vi x^i),
$$ {#eq-newton-residual}
where $\vi R(\vi x) = - \vi F(\vi x)$ is the *residual*, and $\diff \vi x^{i+1} = \vi x^{i+1} - \vi x^i$ is the *displacement*, which play the role of unknowns in ([-@eq-newton-residual]). As a careful reader might notice, instead of requiring an inverse of the Jacobian matrix $\Jacobi_i$, we have translated into a linear system of equations. If $\Jacobi_i\Inv$ exists and is numerically stable^[In such case we can calculate it straight or implicitly via so-called *left division*, which in Julia relies on pivoted QR decomposition.], then we can use it to solve ([-@eq-newton-residual]). On the other hand, if $\Jacobi_i$ is badly conditioned (or singular), so $\Jacobi_i\Inv$ cannot be reliably found, then one can use iterative methods to find an approximate solution. Assuming $\diff \vi x^{i+1}$ is the solution to ([-@eq-newton-residual]), next iteration for ([-@eq-newton-iter]) is computed as
$$
\vi x^{i+1} = \vi x^i + \diff \vi x^{i+1}.
$$

There are many possible stopping conditions for this iterative Newton's method, but often one can see
$$
\norm{\vi x^i - \vi x^{i-1}} \leq \ve_{\text{err}} \; \& \; \norm{\vi R(\vi x^i)} \leq \ve_{\text{res}},
$$
where $\ve_{\text{err}}$ is the given tolerance for the solution error and $\ve_{\text{res}}$ for the residual.

::: {.callout-note #nte-newton-method-modifications}
##### Modifications to Newton's method
Here, we have only discussed the standard Newton's method, but there exists a number of modifications including Newton-chord method, Newton-Broyden method or various quasi-Newton methods.
:::